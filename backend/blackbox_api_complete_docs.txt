# Requests

> Learn about requests to BLACKBOX AI API

## Completions Request Format

Here is the request schema as a TypeScript type. This will be the body of your `POST` request to the `/api/chat/completions` endpoint.

For a complete list of parameters, see the [Parameters](/api-reference/parameters).

<CodeGroup>
  ```typescript Request Schema theme={null}
  // Definitions of subtypes are below
  type Request = {
    // Either "messages" or "prompt" is required
    messages?: Message[];
    prompt?: string;

    // If "model" is unspecified, uses the user's default
    model?: string; // See "Supported Models" section

    // Allows to force the model to produce specific output format.
    // See models page and note on this docs page for which models support it.
    response_format?: { type: 'json_object' };

    stop?: string | string[];
    stream?: boolean; // Enable streaming

    // See LLM Parameters (openrouter.ai/docs/api-reference/parameters)
    max_tokens?: number; // Range: [1, context_length)
    temperature?: number; // Range: [0, 2]

    // Tool calling
    // Will be passed down as-is for providers implementing OpenAI's interface.
    // For providers with custom interfaces, we transform and map the properties.
    // Otherwise, we transform the tools into a YAML template. The model responds with an assistant message.
    // See models supporting tool calling: openrouter.ai/models?supported_parameters=tools
    tools?: Tool[];
    tool_choice?: ToolChoice;

    // Advanced optional parameters
    seed?: number; // Integer only
    top_p?: number; // Range: (0, 1]
    top_k?: number; // Range: [1, Infinity) Not available for OpenAI models
    frequency_penalty?: number; // Range: [-2, 2]
    presence_penalty?: number; // Range: [-2, 2]
    repetition_penalty?: number; // Range: (0, 2]
    logit_bias?: { [key: number]: number };
    top_logprobs: number; // Integer only
    min_p?: number; // Range: [0, 1]
    top_a?: number; // Range: [0, 1]

    // Reduce latency by providing the model with a predicted output
    // https://platform.openai.com/docs/guides/latency-optimization#use-predicted-outputs
    prediction?: { type: 'content'; content: string };

    // OpenRouter-only parameters
    // See "Prompt Transforms" section: openrouter.ai/docs/transforms
    transforms?: string[];
    // See "Model Routing" section: openrouter.ai/docs/model-routing
    models?: string[];
    route?: 'fallback';
    // See "Provider Routing" section: openrouter.ai/docs/provider-routing
    provider?: ProviderPreferences;
    user?: string; // A stable identifier for your end-users. Used to help detect and prevent abuse.
  };

  // Subtypes:

  type TextContent = {
    type: 'text';
    text: string;
  };

  type ImageContentPart = {
    type: 'image_url';
    image_url: {
      url: string; // URL or base64 encoded image data
      detail?: string; // Optional, defaults to "auto"
    };
  };

  type ContentPart = TextContent | ImageContentPart;

  type Message =
    | {
        role: 'user' | 'assistant' | 'system';
        // ContentParts are only for the "user" role:
        content: string | ContentPart[];
        // If "name" is included, it will be prepended like this
        // for non-OpenAI models: `{name}: {content}`
        name?: string;
      }
    | {
        role: 'tool';
        content: string;
        tool_call_id: string;
        name?: string;
      };

  type FunctionDescription = {
    description?: string;
    name: string;
    parameters: object; // JSON Schema object
  };

  type Tool = {
    type: 'function';
    function: FunctionDescription;
  };

  type ToolChoice =
    | 'none'
    | 'auto'
    | {
        type: 'function';
        function: {
          name: string;
        };
      };
  ```
</CodeGroup>

The `response_format` parameter ensures you receive a structured response from the LLM. The parameter is only supported by OpenAI models and some others

## Assistant Prefill

BLACKBOX AI supports asking models to complete a partial response. This can be useful for guiding models to respond in a certain way.

To use this features, simply include a message with `role: "assistant"` at the end of your `messages` array.

<CodeGroup>
  ```typescript TypeScript theme={null}
  const API_KEY = "YOUR_API_KEY";

  fetch('https://api.blackbox.ai/api/chat/completions', {
    method: 'POST',
    headers: {
      Authorization: 'Bearer ${API_KEY}',
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'BLACKBOX AI/openai/gpt-4o',
      messages: [
        { role: 'user', content: 'What is the meaning of life?' },
        { role: 'assistant', content: "I'm not sure, but my best guess is" },
      ],
    }),
  });
  ```
</CodeGroup>


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.blackbox.ai/llms.txt


# Requests

> Learn about requests to BLACKBOX AI API

## Completions Request Format

Here is the request schema as a TypeScript type. This will be the body of your `POST` request to the `/api/chat/completions` endpoint.

For a complete list of parameters, see the [Parameters](/api-reference/parameters).

<CodeGroup>
  ```typescript Request Schema theme={null}
  // Definitions of subtypes are below
  type Request = {
    // Either "messages" or "prompt" is required
    messages?: Message[];
    prompt?: string;

    // If "model" is unspecified, uses the user's default
    model?: string; // See "Supported Models" section

    // Allows to force the model to produce specific output format.
    // See models page and note on this docs page for which models support it.
    response_format?: { type: 'json_object' };

    stop?: string | string[];
    stream?: boolean; // Enable streaming

    // See LLM Parameters (openrouter.ai/docs/api-reference/parameters)
    max_tokens?: number; // Range: [1, context_length)
    temperature?: number; // Range: [0, 2]

    // Tool calling
    // Will be passed down as-is for providers implementing OpenAI's interface.
    // For providers with custom interfaces, we transform and map the properties.
    // Otherwise, we transform the tools into a YAML template. The model responds with an assistant message.
    // See models supporting tool calling: openrouter.ai/models?supported_parameters=tools
    tools?: Tool[];
    tool_choice?: ToolChoice;

    // Advanced optional parameters
    seed?: number; // Integer only
    top_p?: number; // Range: (0, 1]
    top_k?: number; // Range: [1, Infinity) Not available for OpenAI models
    frequency_penalty?: number; // Range: [-2, 2]
    presence_penalty?: number; // Range: [-2, 2]
    repetition_penalty?: number; // Range: (0, 2]
    logit_bias?: { [key: number]: number };
    top_logprobs: number; // Integer only
    min_p?: number; // Range: [0, 1]
    top_a?: number; // Range: [0, 1]

    // Reduce latency by providing the model with a predicted output
    // https://platform.openai.com/docs/guides/latency-optimization#use-predicted-outputs
    prediction?: { type: 'content'; content: string };

    // OpenRouter-only parameters
    // See "Prompt Transforms" section: openrouter.ai/docs/transforms
    transforms?: string[];
    // See "Model Routing" section: openrouter.ai/docs/model-routing
    models?: string[];
    route?: 'fallback';
    // See "Provider Routing" section: openrouter.ai/docs/provider-routing
    provider?: ProviderPreferences;
    user?: string; // A stable identifier for your end-users. Used to help detect and prevent abuse.
  };

  // Subtypes:

  type TextContent = {
    type: 'text';
    text: string;
  };

  type ImageContentPart = {
    type: 'image_url';
    image_url: {
      url: string; // URL or base64 encoded image data
      detail?: string; // Optional, defaults to "auto"
    };
  };

  type ContentPart = TextContent | ImageContentPart;

  type Message =
    | {
        role: 'user' | 'assistant' | 'system';
        // ContentParts are only for the "user" role:
        content: string | ContentPart[];
        // If "name" is included, it will be prepended like this
        // for non-OpenAI models: `{name}: {content}`
        name?: string;
      }
    | {
        role: 'tool';
        content: string;
        tool_call_id: string;
        name?: string;
      };

  type FunctionDescription = {
    description?: string;
    name: string;
    parameters: object; // JSON Schema object
  };

  type Tool = {
    type: 'function';
    function: FunctionDescription;
  };

  type ToolChoice =
    | 'none'
    | 'auto'
    | {
        type: 'function';
        function: {
          name: string;
        };
      };
  ```
</CodeGroup>

The `response_format` parameter ensures you receive a structured response from the LLM. The parameter is only supported by OpenAI models and some others

## Assistant Prefill

BLACKBOX AI supports asking models to complete a partial response. This can be useful for guiding models to respond in a certain way.

To use this features, simply include a message with `role: "assistant"` at the end of your `messages` array.

<CodeGroup>
  ```typescript TypeScript theme={null}
  const API_KEY = "YOUR_API_KEY";

  fetch('https://api.blackbox.ai/api/chat/completions', {
    method: 'POST',
    headers: {
      Authorization: 'Bearer ${API_KEY}',
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'BLACKBOX AI/openai/gpt-4o',
      messages: [
        { role: 'user', content: 'What is the meaning of life?' },
        { role: 'assistant', content: "I'm not sure, but my best guess is" },
      ],
    }),
  });
  ```
</CodeGroup>


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.blackbox.ai/llms.txt



# Create Chat Completion

> Send a chat completion request. Find your [API Key](https://app.blackbox.ai/dashboard).

## Headers

<ParamField header="Authorization" type="string" required>
  API Key of the from `Bearer <api_key>`,  you can get it from [here](https://app.blackbox.ai/dashboard).
</ParamField>

## Request

<ParamField body="model" type="string" required>
  The model ID to use. See the [Chat Models page](/api-reference/models/chat-models)
</ParamField>

<ParamField body="messages" type="array" required>
  Array of message objects containing the conversation history.

  <Expandable title="Message Object">
    <ParamField body="role" type="string" required>
      The role of the message author. One of `system`, `user`, `assistant`, or `tool`.
    </ParamField>

    <ParamField body="content" type="string | array">
      The content of the message. Can be a string or array of content parts for multimodal inputs.
    </ParamField>

    <ParamField body="name" type="string">
      An optional name for the participant. Provides the model information to differentiate between participants of the same role.
    </ParamField>

    <ParamField body="tool_call_id" type="string">
      For tool messages, the ID of the tool call this message is responding to.
    </ParamField>
  </Expandable>
</ParamField>

<ParamField body="models" type="array">
  Alternate list of models for routing overrides.
</ParamField>

<ParamField body="provider" type="object">
  Preferences for provider routing.
</ParamField>

<ParamField body="transforms" type="array">
  List of prompt transforms (OpenRouter-only).
</ParamField>

<ParamField body="stream" type="boolean">
  Enable streaming of results via Server-Sent Events.
</ParamField>

<ParamField body="max_tokens" type="integer">
  Maximum number of tokens to generate (range: \[1, context\_length)).
</ParamField>

<ParamField body="temperature" type="number">
  Sampling temperature (range: \[0, 2]).
</ParamField>

<ParamField body="seed" type="integer">
  Seed for deterministic outputs.
</ParamField>

<ParamField body="top_p" type="number">
  Top-p sampling value (range: (0, 1]).
</ParamField>

<ParamField body="top_k" type="integer">
  Top-k sampling value (range: \[1, Infinity)).
</ParamField>

<ParamField body="frequency_penalty" type="number">
  Frequency penalty (range: \[-2, 2]).
</ParamField>

<ParamField body="presence_penalty" type="number">
  Presence penalty (range: \[-2, 2]).
</ParamField>

<ParamField body="repetition_penalty" type="number">
  Repetition penalty (range: (0, 2]).
</ParamField>

<ParamField body="logit_bias" type="object">
  Mapping of token IDs to bias values.
</ParamField>

<ParamField body="top_logprobs" type="integer">
  Number of top log probabilities to return.
</ParamField>

<ParamField body="min_p" type="number">
  Minimum probability threshold (range: \[0, 1]).
</ParamField>

<ParamField body="top_a" type="number">
  Alternate top sampling parameter (range: \[0, 1]).
</ParamField>

<ParamField body="stop" type="array">
  Stop sequences - generation will stop if any of these strings are encountered.
</ParamField>

<ParamField body="tools" type="array">
  Tool definitions following OpenAI's tool calling format.

  <Expandable title="Tool Object">
    <ParamField body="type" type="string">
      Type of tool, typically `function`.
    </ParamField>

    <ParamField body="function" type="object">
      Function definition.

      <Expandable title="Function Definition">
        <ParamField body="name" type="string">
          Name of the function.
        </ParamField>

        <ParamField body="description" type="string">
          Description of what the function does.
        </ParamField>

        <ParamField body="parameters" type="object">
          JSON Schema object defining the function parameters.
        </ParamField>
      </Expandable>
    </ParamField>
  </Expandable>
</ParamField>

<ParamField body="tool_choice" type="string | object">
  Controls which (if any) tool is called by the model.

  * `none` - Model will not call any tool
  * `auto` - Model can pick between generating a message or calling tools
  * `required` - Model must call one or more tools
  * Or specify a particular tool via `{"type": "function", "function": {"name": "function_name"}}`
</ParamField>

<ParamField body="response_format" type="object">
  Enforce structured output format.
</ParamField>

<ParamField body="user" type="string">
  A stable identifier for your end-users. Used to help detect and prevent abuse.
</ParamField>

## Response

<ResponseField name="id" type="string">
  Unique identifier for the chat completion.
</ResponseField>

<ResponseField name="created" type="integer">
  Unix timestamp when the completion was created.
</ResponseField>

<ResponseField name="model" type="string">
  The model used for the completion.
</ResponseField>

<ResponseField name="object" type="string">
  Object type, always `chat.completion` or `chat.completion.chunk` for streaming.
</ResponseField>

<ResponseField name="system_fingerprint" type="string | null">
  System fingerprint for the model configuration.
</ResponseField>

<ResponseField name="choices" type="array">
  Array of completion choices.

  <Expandable title="Choice Object">
    <ResponseField name="finish_reason" type="string">
      Reason the generation stopped. Options: `stop`, `length`, `content_filter`, `tool_calls`, `error`.
    </ResponseField>

    <ResponseField name="index" type="integer">
      Index of the choice in the list.
    </ResponseField>

    <ResponseField name="message" type="object">
      The generated message.

      <Expandable title="Message Object">
        <ResponseField name="content" type="string | null">
          The generated content.
        </ResponseField>

        <ResponseField name="role" type="string">
          Role of the message author, typically `assistant`.
        </ResponseField>

        <ResponseField name="tool_calls" type="array | null">
          Tool calls made by the assistant.

          <Expandable title="Tool Call Object">
            <ResponseField name="id" type="string">
              Unique identifier for the tool call.
            </ResponseField>

            <ResponseField name="type" type="string">
              Type of tool, typically `function`.
            </ResponseField>

            <ResponseField name="function" type="object">
              The function call details.

              <Expandable title="Function Object">
                <ResponseField name="name" type="string">
                  Name of the function being called.
                </ResponseField>

                <ResponseField name="arguments" type="string">
                  JSON string of arguments for the function.
                </ResponseField>
              </Expandable>
            </ResponseField>
          </Expandable>
        </ResponseField>

        <ResponseField name="annotations" type="array | null">
          Annotations containing source citations and references. Available when using models with web search capabilities like `blackbox-search`.

          <Expandable title="Annotation Object">
            <ResponseField name="type" type="string">
              Type of annotation. Currently supports `url_citation`.
            </ResponseField>

            <ResponseField name="url_citation" type="object">
              Citation information for web sources.

              <Expandable title="URL Citation Object">
                <ResponseField name="url" type="string">
                  The URL of the cited source.
                </ResponseField>

                <ResponseField name="title" type="string">
                  The title of the web page or article.
                </ResponseField>

                <ResponseField name="content" type="string">
                  Excerpt or summary of the content from the source (if available).
                </ResponseField>

                <ResponseField name="start_index" type="integer">
                  The character index where the citation begins in the message content.
                </ResponseField>

                <ResponseField name="end_index" type="integer">
                  The character index where the citation ends in the message content.
                </ResponseField>
              </Expandable>
            </ResponseField>
          </Expandable>
        </ResponseField>

        <ResponseField name="function_call" type="object | null">
          Deprecated function call field (use `tool_calls` instead).
        </ResponseField>
      </Expandable>
    </ResponseField>

    <ResponseField name="provider_specific_fields" type="object">
      Provider-specific response fields.

      <Expandable title="Provider Specific Fields">
        <ResponseField name="native_finish_reason" type="string">
          Raw finish reason from the underlying provider.
        </ResponseField>
      </Expandable>
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="usage" type="object">
  Token usage information.

  <Expandable title="Usage Object">
    <ResponseField name="completion_tokens" type="integer">
      Number of tokens in the completion.
    </ResponseField>

    <ResponseField name="prompt_tokens" type="integer">
      Number of tokens in the prompt.
    </ResponseField>

    <ResponseField name="total_tokens" type="integer">
      Total number of tokens used (prompt + completion).
    </ResponseField>

    <ResponseField name="completion_tokens_details" type="object">
      Detailed breakdown of completion tokens.

      <Expandable title="Completion Tokens Details">
        <ResponseField name="accepted_prediction_tokens" type="integer | null">
          Number of accepted prediction tokens.
        </ResponseField>

        <ResponseField name="audio_tokens" type="integer | null">
          Number of audio tokens in the completion.
        </ResponseField>

        <ResponseField name="reasoning_tokens" type="integer">
          Number of reasoning/thinking tokens used.
        </ResponseField>

        <ResponseField name="rejected_prediction_tokens" type="integer | null">
          Number of rejected prediction tokens.
        </ResponseField>
      </Expandable>
    </ResponseField>

    <ResponseField name="prompt_tokens_details" type="object">
      Detailed breakdown of prompt tokens.

      <Expandable title="Prompt Tokens Details">
        <ResponseField name="audio_tokens" type="integer">
          Number of audio tokens in the prompt.
        </ResponseField>

        <ResponseField name="cached_tokens" type="integer">
          Number of cached tokens used from previous requests.
        </ResponseField>
      </Expandable>
    </ResponseField>
  </Expandable>
</ResponseField>

<ResponseField name="provider" type="string">
  The provider that served the request.
</ResponseField>

<RequestExample>
  ```bash cURL theme={null}
  curl -X POST https://api.blackbox.ai/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
      "model": "blackboxai/openai/gpt-4",
      "messages": [
          {
              "role": "user",
              "content": "What is the capital of France?"
          }
      ],
      "temperature": 0.7,
      "max_tokens": 256,
      "stream": false
  }'
  ```

  ```javascript Node.js theme={null}
  const API_KEY = "YOUR_API_KEY";
  const API_URL = "https://api.blackbox.ai/chat/completions";

  const data = {
      "model": "blackboxai/openai/gpt-4",
      "messages": [
          {
              "role": "user",
              "content": "What is the capital of France?"
          }
      ],
      "temperature": 0.7,
      "max_tokens": 256,
      "stream": false
  };

  const response = await fetch(API_URL, {
      method: 'POST',
      headers: {
          'Authorization': `Bearer ${API_KEY}`,
          'Content-Type': 'application/json'
      },
      body: JSON.stringify(data)
  });

  const responseData = await response.json();
  console.log(responseData);
  ```

  ```python Python theme={null}
  import requests

  API_KEY = "YOUR_API_KEY"
  API_URL = "https://api.blackbox.ai/chat/completions"

  headers = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
  }

  data = {
      "model": "blackboxai/openai/gpt-4",
      "messages": [
          {
              "role": "user",
              "content": "What is the capital of France?"
          }
      ],
      "temperature": 0.7,
      "max_tokens": 256,
      "stream": False
  }

  response = requests.post(API_URL, headers=headers, json=data)
  print(response.json())
  ```
</RequestExample>

<ResponseExample>
  ```json Response theme={null}
  {
    "id":"gen-...",
    "created":1757140020,
    "model":"openai/gpt-4",
    "object":"chat.completion",
    "system_fingerprint":"None",
    "choices":[
      {
        "finish_reason":"stop",
        "index":0,
        "message":{
          "content":"The capital of France is Paris.",
          "role":"assistant",
          "tool_calls":"None",
          "function_call":"None"
        },
        "provider_specific_fields":{
          "native_finish_reason":"stop"
        }
      }
    ],
    "usage":{
      "completion_tokens":7,
      "prompt_tokens":14,
      "total_tokens":21,
      "completion_tokens_details":{
        "accepted_prediction_tokens":"None",
        "audio_tokens":"None",
        "reasoning_tokens":0,
        "rejected_prediction_tokens":"None"
      },
      "prompt_tokens_details":{
        "audio_tokens":0,
        "cached_tokens":0
      }
    },
    "provider":"OpenAI"
  }
  ```
</ResponseExample>


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.blackbox.ai/llms.txt




# Get Task Details

> Retrieve detailed information about a specific task including status, progress, logs, and execution results.

This endpoint allows you to retrieve comprehensive details about a task that has been created. You can monitor task progress, view execution logs, analyze diffs, and check completion status.

## Authentication

To use this API, you need a BLACKBOX API Key. Follow these steps to get your API key:

1. **Click on your Profile Image** in the top right corner at [cloud.blackbox.ai](https://cloud.blackbox.ai)
2. **Click on "BLACKBOX API Token"** from the dropdown menu
3. **Copy the existing token** or **click "Generate"** if you don't have one yet

Your API key will be in the format: `bb_xxxxxxxxxxxxxxxxxxxxxx`

## Headers

<ParamField header="Authorization" type="string" required>
  API Key of the form `Bearer <api_key>`.

  Example: `Bearer bb_b41b647ffbfed27f61656049d3eaeef3d903cc503345d9eb80080d98bc0`
</ParamField>

## Path Parameters

<ParamField path="taskId" type="string" required>
  The unique identifier of the task you want to retrieve.

  Example: `9qQe2F8Z_nXx9-eJA0BD6`
</ParamField>

## Response Fields

### Task Object

<ResponseField name="id" type="string">
  Unique identifier for the task.
</ResponseField>

<ResponseField name="userId" type="string">
  Email or ID of the user who created the task.
</ResponseField>

<ResponseField name="prompt" type="string">
  The original task description or instruction provided.
</ResponseField>

<ResponseField name="repoUrl" type="string">
  GitHub repository URL the task was executed on.
</ResponseField>

<ResponseField name="selectedAgent" type="string">
  The AI agent used for executing the task (claude, blackbox, codex, gemini).
</ResponseField>

<ResponseField name="selectedModel" type="string">
  The specific AI model used with the selected agent.
</ResponseField>

<ResponseField name="status" type="string">
  Current status of the task.

  Possible values:

  * `pending` - Task is queued and waiting to start
  * `running` - Task is currently being executed
  * `completed` - Task finished successfully
  * `failed` - Task encountered an error
  * `cancelled` - Task was cancelled by user
</ResponseField>

<ResponseField name="progress" type="number">
  Task completion percentage (0-100).
</ResponseField>

<ResponseField name="logs" type="array">
  Array of log entries generated during task execution.
</ResponseField>

<ResponseField name="selectedBranch" type="string">
  The branch that was worked on in the repository.
</ResponseField>

<ResponseField name="branchName" type="string">
  The new branch name created for the task changes.
</ResponseField>

<ResponseField name="sandboxId" type="string">
  Identifier for the sandbox environment used for execution.
</ResponseField>

<ResponseField name="merged" type="boolean">
  Whether the changes have been merged into the target branch.
</ResponseField>

<ResponseField name="prNumber" type="number">
  Pull request number if a PR was created (null otherwise).
</ResponseField>

<ResponseField name="prUrl" type="string">
  URL to the pull request if created.
</ResponseField>

<ResponseField name="multiLaunch" type="boolean">
  Whether multiple agents were launched for this task.
</ResponseField>

<ResponseField name="selectedAgents" type="array">
  Array of agent configurations when using multi-launch mode.

  Each object contains:

  * `agent` - Agent name
  * `model` - Model identifier
</ResponseField>

<ResponseField name="agentExecutions" type="array">
  Detailed execution information for each agent in multi-launch mode.

  Each object contains:

  * `agent` - Agent name
  * `status` - Execution status
  * `gitDiff` - Git diff of changes made
  * `branchName` - Branch created by this agent
  * `executedAt` - Execution start timestamp
  * `completedAt` - Execution completion timestamp
</ResponseField>

<ResponseField name="diffAnalysis" type="object">
  Analysis comparing different agent implementations (for multi-launch tasks).

  Contains:

  * `analysis` - Detailed markdown analysis of implementations
  * `bestAgent` - Name of the agent with the best implementation
  * `analyzedAt` - Timestamp of analysis
</ResponseField>

<ResponseField name="diffStats" type="object">
  Statistics about code changes made.

  Contains:

  * `totalLinesAdded` - Number of lines added
  * `totalLinesRemoved` - Number of lines removed
  * `totalFilesChanged` - Number of files modified
  * `initialCommitSha` - SHA of the initial commit
</ResponseField>

<ResponseField name="cumulativeDiff" type="string">
  Complete git diff of all changes made across all agents.
</ResponseField>

<ResponseField name="checkpoint" type="object">
  Checkpoint information for each agent's execution stage.
</ResponseField>

<ResponseField name="error" type="string">
  Error message if the task failed (null otherwise).
</ResponseField>

<ResponseField name="createdAt" type="string">
  ISO 8601 timestamp when the task was created.
</ResponseField>

<ResponseField name="updatedAt" type="string">
  ISO 8601 timestamp when the task was last updated.
</ResponseField>

<ResponseField name="completedAt" type="string">
  ISO 8601 timestamp when the task completed (null if still running).
</ResponseField>

<ResponseField name="isPublic" type="boolean">
  Whether the task is publicly accessible.
</ResponseField>

<RequestExample>
  ```bash cURL theme={null}
  curl 'https://cloud.blackbox.ai/api/tasks/9qQe2F8Z_nXx9-eJA0BD6' \
    -H 'Authorization: Bearer bb_YOUR_API_KEY' \
    -H 'Accept: application/json'
  ```

  ```javascript Node.js theme={null}
  const API_KEY = "bb_YOUR_API_KEY";
  const TASK_ID = "9qQe2F8Z_nXx9-eJA0BD6";
  const API_URL = `https://cloud.blackbox.ai/api/tasks/${TASK_ID}`;

  const response = await fetch(API_URL, {
      method: "GET",
      headers: {
          Authorization: `Bearer ${API_KEY}`,
          Accept: "application/json",
      },
  });

  const data = await response.json();
  console.log(data);
  ```

  ```python Python theme={null}
  import requests

  API_KEY = "bb_YOUR_API_KEY"
  TASK_ID = "9qQe2F8Z_nXx9-eJA0BD6"
  API_URL = f"https://cloud.blackbox.ai/api/tasks/{TASK_ID}"

  headers = {
      "Authorization": f"Bearer {API_KEY}",
      "Accept": "application/json"
  }

  response = requests.get(API_URL, headers=headers)
  print(response.json())
  ```

  ```go Go theme={null}
  package main

  import (
      "fmt"
      "io"
      "net/http"
  )

  func main() {
      apiKey := "bb_YOUR_API_KEY"
      taskId := "9qQe2F8Z_nXx9-eJA0BD6"
      url := fmt.Sprintf("https://cloud.blackbox.ai/api/tasks/%s", taskId)

      req, _ := http.NewRequest("GET", url, nil)
      req.Header.Add("Authorization", fmt.Sprintf("Bearer %s", apiKey))
      req.Header.Add("Accept", "application/json")

      client := &http.Client{}
      resp, err := client.Do(req)
      if err != nil {
          panic(err)
      }
      defer resp.Body.Close()

      body, _ := io.ReadAll(resp.Body)
      fmt.Println(string(body))
  }
  ```
</RequestExample>

<ResponseExample>
  ```json Success Response - Completed Task theme={null}
  {
    "task": {
      "id": "9qQe2F8Z_nXx9-eJA0BD6",
      "userId": "user@example.com",
      "teamId": null,
      "prompt": "Add Stripe payment gateway",
      "repoUrl": "https://github.com/username/repository.git",
      "selectedAgent": "claude",
      "selectedModel": "blackboxai/anthropic/claude-sonnet-4.5",
      "installDependencies": false,
      "maxDuration": 300,
      "keepAlive": true,
      "status": "completed",
      "progress": 100,
      "logs": [],
      "followupMessages": null,
      "checkpoint": {
        "claude": {
          "stage": "diff_analyzed",
          "timestamp": "2025-11-20T23:41:36.930Z"
        },
        "blackbox": {
          "stage": "diff_analyzed",
          "timestamp": "2025-11-20T23:41:37.051Z"
        }
      },
      "error": null,
      "selectedBranch": "main",
      "branchName": "feature/add-stripe-payment-j6k-claude",
      "sandboxUrl": null,
      "sandboxId": "sbx_XJV19Afr0gXFrc723Asn2bfSb3H8",
      "agentSandboxConfig": {
        "claude": {
          "sandboxId": "sbx_XJV19Afr0gXFrc723Asn2bfSb3H8",
          "branchName": "feature/add-stripe-payment-j6k-claude"
        }
      },
      "merged": false,
      "prNumber": null,
      "prUrl": null,
      "multiLaunch": true,
      "selectedAgents": [
        {
          "agent": "claude",
          "model": "blackboxai/anthropic/claude-sonnet-4.5"
        },
        {
          "agent": "blackbox",
          "model": "blackboxai/blackbox-pro"
        }
      ],
      "agentExecutions": [
        {
          "agent": "claude",
          "status": "completed",
          "gitDiff": "diff --git a/src/payment/stripe.ts b/src/payment/stripe.ts\nnew file mode 100644\nindex 0000000..1234567\n--- /dev/null\n+++ b/src/payment/stripe.ts\n@@ -0,0 +1,85 @@\n+import Stripe from 'stripe';\n+\n+export const stripe = new Stripe(process.env.STRIPE_SECRET_KEY);\n+...",
          "branchName": "feature/add-stripe-payment-j6k-claude",
          "executedAt": "2025-11-20T23:37:24.186Z",
          "completedAt": "2025-11-20T23:39:43.833Z"
        },
        {
          "agent": "blackbox",
          "status": "completed",
          "gitDiff": "diff --git a/src/services/payment.ts b/src/services/payment.ts\nnew file mode 100644\nindex 0000000..7890abc\n--- /dev/null\n+++ b/src/services/payment.ts\n@@ -0,0 +1,92 @@\n+const stripe = require('stripe')(process.env.STRIPE_SECRET_KEY);\n+...",
          "branchName": "feature/add-stripe-payment-j6k-blackbox",
          "executedAt": "2025-11-20T23:37:24.186Z",
          "completedAt": "2025-11-20T23:41:11.258Z"
        }
      ],
      "diffAnalysis": {
        "analysis": "# Best Implementation: CLAUDE\n\n## Analysis Reasoning\n\nClaude's implementation demonstrates superior understanding of Stripe integration best practices. The code uses TypeScript with proper type definitions, implements error handling, and follows modern ES6+ patterns. The implementation includes webhook handling, proper environment variable management, and comprehensive payment flow coverage including checkout sessions, payment intents, and subscription management.\n\n## Detailed Agent Analysis\n\n### CLAUDE (Winner)\n\n**Score:** 9/10\n\n**Strengths:**\n- Uses TypeScript with proper Stripe type definitions\n- Implements comprehensive error handling and logging\n- Follows modern ES6+ module patterns\n- Includes webhook signature verification\n- Proper environment variable management\n- Implements both one-time payments and subscriptions\n- Clean separation of concerns with service layer\n\n**Weaknesses:**\n- Could benefit from additional unit tests\n- Missing some edge case handling for refunds\n\n---\n\n### BLACKBOX\n\n**Score:** 7/10\n\n**Strengths:**\n- Complete Stripe integration implementation\n- Includes basic error handling\n- Covers essential payment flows\n- Functional webhook implementation\n\n**Weaknesses:**\n- Uses CommonJS instead of ES6 modules\n- Lacks TypeScript type safety\n- Less comprehensive error handling\n- Missing some advanced Stripe features\n\n---\n\n## Conclusion\n\nClaude's implementation wins due to its use of TypeScript, superior error handling, and adherence to modern JavaScript best practices. The implementation is production-ready with proper type safety and comprehensive coverage of Stripe payment flows.",
        "bestAgent": "claude",
        "analyzedAt": "2025-11-20T23:41:36.810Z"
      },
      "diffStats": {
        "totalLinesAdded": 247,
        "initialCommitSha": "dcee312deecf502c5a161d9067bf974dd9874bcf",
        "totalFilesChanged": 4,
        "totalLinesRemoved": 12
      },
      "cumulativeDiff": "diff --git a/src/payment/stripe.ts b/src/payment/stripe.ts\nnew file mode 100644\nindex 0000000..1234567\n--- /dev/null\n+++ b/src/payment/stripe.ts\n@@ -0,0 +1,85 @@\n+import Stripe from 'stripe';\n+\n+export const stripe = new Stripe(process.env.STRIPE_SECRET_KEY);\n+...",
      "taskSource": "manual",
      "scheduledTaskId": null,
      "repoInstructions": null,
      "environmentVariables": null,
      "testAccounts": null,
      "autoDeployEnabled": false,
      "deploymentProvider": "vercel",
      "vercelDeploymentSettings": null,
      "gcloudDeploymentSettings": null,
      "deployments": null,
      "lock": null,
      "createdAt": "2025-11-20T23:37:17.761Z",
      "updatedAt": "2025-11-20T23:41:39.024Z",
      "completedAt": "2025-11-20T23:41:39.024Z",
      "slackUserId": null,
      "slackTeamId": null,
      "slackChannelId": null,
      "slackMessageTs": null,
      "badge": null,
      "batchId": null,
      "isPublic": false,
      "isEmptyGitUser": false,
      "metaData": null
    }
  }
  ```

  ```json Success Response - Running Task theme={null}
  {
    "task": {
      "id": "abc123xyz456",
      "userId": "user@example.com",
      "teamId": null,
      "prompt": "Add unit tests for authentication module",
      "repoUrl": "https://github.com/username/repository.git",
      "selectedAgent": "blackbox",
      "selectedModel": "blackboxai/blackbox-pro",
      "installDependencies": false,
      "maxDuration": 300,
      "keepAlive": false,
      "status": "running",
      "progress": 45,
      "logs": [
        "Cloning repository...",
        "Analyzing codebase...",
        "Generating test cases..."
      ],
      "followupMessages": null,
      "checkpoint": {
        "blackbox": {
          "stage": "executing",
          "timestamp": "2025-11-21T10:15:30.123Z"
        }
      },
      "error": null,
      "selectedBranch": "main",
      "branchName": "tests/add-auth-tests-xyz",
      "sandboxUrl": null,
      "sandboxId": "sbx_ABC123XYZ456",
      "agentSandboxConfig": null,
      "merged": false,
      "prNumber": null,
      "prUrl": null,
      "multiLaunch": false,
      "selectedAgents": null,
      "agentExecutions": null,
      "diffAnalysis": null,
      "diffStats": null,
      "cumulativeDiff": null,
      "taskSource": "manual",
      "scheduledTaskId": null,
      "repoInstructions": null,
      "environmentVariables": null,
      "testAccounts": null,
      "autoDeployEnabled": false,
      "deploymentProvider": "vercel",
      "vercelDeploymentSettings": null,
      "gcloudDeploymentSettings": null,
      "deployments": null,
      "lock": null,
      "createdAt": "2025-11-21T10:10:00.000Z",
      "updatedAt": "2025-11-21T10:15:30.123Z",
      "completedAt": null,
      "slackUserId": null,
      "slackTeamId": null,
      "slackChannelId": null,
      "slackMessageTs": null,
      "badge": null,
      "batchId": null,
      "isPublic": false,
      "isEmptyGitUser": false,
      "metaData": null
    }
  }
  ```

  ```json Error Response - Task Not Found theme={null}
  {
    "error": "Task not found",
    "message": "No task found with ID: invalid_task_id",
    "status": 404
  }
  ```

  ```json Error Response - Unauthorized theme={null}
  {
    "error": "Unauthorized",
    "message": "Invalid or missing API key",
    "status": 401
  }
  ```
</ResponseExample>

## Use Cases

### Polling for Task Completion

You can poll this endpoint to monitor task progress:

```javascript  theme={null}
async function waitForTaskCompletion(taskId) {
  const API_KEY = "bb_YOUR_API_KEY";
  const API_URL = `https://cloud.blackbox.ai/api/tasks/${taskId}`;
  
  while (true) {
    const response = await fetch(API_URL, {
      headers: {
        Authorization: `Bearer ${API_KEY}`,
        Accept: "application/json",
      },
    });
    
    const { task } = await response.json();
    
    console.log(`Status: ${task.status}, Progress: ${task.progress}%`);
    
    if (task.status === "completed" || task.status === "failed") {
      return task;
    }
    
    // Wait 5 seconds before polling again
    await new Promise(resolve => setTimeout(resolve, 5000));
  }
}
```

### Analyzing Multi-Agent Results

For tasks with `multiLaunch: true`, you can compare different agent implementations:

```javascript  theme={null}
const { task } = await response.json();

if (task.multiLaunch && task.diffAnalysis) {
  console.log("Best Agent:", task.diffAnalysis.bestAgent);
  console.log("Analysis:", task.diffAnalysis.analysis);
  
  task.agentExecutions.forEach(execution => {
    console.log(`\n${execution.agent}:`);
    console.log(`  Status: ${execution.status}`);
    console.log(`  Branch: ${execution.branchName}`);
    console.log(`  Duration: ${
      new Date(execution.completedAt) - new Date(execution.executedAt)
    }ms`);
  });
}
```

### Retrieving Code Changes

Access the git diff to see what changes were made:

```javascript  theme={null}
const { task } = await response.json();

if (task.status === "completed") {
  console.log("Files Changed:", task.diffStats.totalFilesChanged);
  console.log("Lines Added:", task.diffStats.totalLinesAdded);
  console.log("Lines Removed:", task.diffStats.totalLinesRemoved);
  console.log("\nFull Diff:\n", task.cumulativeDiff);
}
```


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.blackbox.ai/llms.txt


# Chat Models

> Explore the AI models available for conversational tasks, text generation, and complex reasoning.

## Overview

Chat models are the foundation of conversational AI. They are designed to understand and generate human-like text, making them perfect for a wide range of applications including chatbots, content creation, summarization, and question-answering systems.

When making a request to the `/chat/completions` endpoint, you must specify one of the following Model IDs. The costs mentioned below are for 1 million tokens.

## Available Chat Models

| **Model Name**                                             | **Model ID**                                                    | **Context Length** | **Input Cost** | **Output Cost** |
| ---------------------------------------------------------- | --------------------------------------------------------------- | ------------------ | -------------- | --------------- |
| xAI: Grok Code Fast 1                                      | blackboxai/x-ai/grok-code-fast-1:free                           | 256000             | Free           | Free            |
| 01.AI: Yi Large                                            | blackboxai/01-ai/yi-large                                       | 32768              | \$3.00         | \$3.00          |
| AI21: Jamba 1.6 Large                                      | blackboxai/ai21/jamba-1.6-large                                 | 256000             | \$2.00         | \$8.00          |
| AI21: Jamba Mini 1.6                                       | blackboxai/ai21/jamba-1.6-mini                                  | 256000             | \$0.20         | \$0.40          |
| Aetherwiing: Starcannon 12B                                | blackboxai/aetherwiing/mn-starcannon-12b                        | 16384              | \$0.80         | \$1.20          |
| Agentica: Deepcoder 14B Preview (free)                     | blackboxai/agentica-org/deepcoder-14b-preview:free              | 96000              | \$0.00         | \$0.00          |
| AionLabs: Aion-1.0                                         | blackboxai/aion-labs/aion-1.0                                   | 131072             | \$4.00         | \$8.00          |
| AionLabs: Aion-1.0-Mini                                    | blackboxai/aion-labs/aion-1.0-mini                              | 131072             | \$0.70         | \$1.40          |
| AionLabs: Aion-RP 1.0 (8B)                                 | blackboxai/aion-labs/aion-rp-llama-3.1-8b                       | 32768              | \$0.20         | \$0.20          |
| AlfredPros: CodeLLaMa 7B Instruct Solidity                 | blackboxai/alfredpros/codellama-7b-instruct-solidity            | 4096               | \$0.80         | \$1.20          |
| Amazon: Nova Lite 1.0                                      | blackboxai/amazon/nova-lite-v1                                  | 300000             | \$0.06         | \$0.24          |
| Amazon: Nova Micro 1.0                                     | blackboxai/amazon/nova-micro-v1                                 | 128000             | \$0.04         | \$0.14          |
| Amazon: Nova Pro 1.0                                       | blackboxai/amazon/nova-pro-v1                                   | 300000             | \$0.80         | \$3.20          |
| Anthropic: Claude 3 Haiku                                  | blackboxai/anthropic/claude-3-haiku                             | 200000             | \$0.25         | \$1.25          |
| Anthropic: Claude 3 Haiku (self-moderated)                 | blackboxai/anthropic/claude-3-haiku:beta                        | 200000             | \$0.25         | \$1.25          |
| Anthropic: Claude 3 Opus                                   | blackboxai/anthropic/claude-3-opus                              | 200000             | \$15.00        | \$75.00         |
| Anthropic: Claude 3 Opus (self-moderated)                  | blackboxai/anthropic/claude-3-opus:beta                         | 200000             | \$15.00        | \$75.00         |
| Anthropic: Claude 3 Sonnet                                 | blackboxai/anthropic/claude-3-sonnet                            | 200000             | \$3.00         | \$15.00         |
| Anthropic: Claude 3 Sonnet (self-moderated)                | blackboxai/anthropic/claude-3-sonnet:beta                       | 200000             | \$3.00         | \$15.00         |
| Anthropic: Claude 3.5 Haiku                                | blackboxai/anthropic/claude-3.5-haiku                           | 200000             | \$0.80         | \$4.00          |
| Anthropic: Claude 3.5 Haiku (2024-10-22)                   | blackboxai/anthropic/claude-3.5-haiku-20241022                  | 200000             | \$0.80         | \$4.00          |
| Anthropic: Claude 3.5 Haiku (2024-10-22) (self-moderated)  | blackboxai/anthropic/claude-3.5-haiku-20241022:beta             | 200000             | \$0.80         | \$4.00          |
| Anthropic: Claude 3.5 Haiku (self-moderated)               | blackboxai/anthropic/claude-3.5-haiku:beta                      | 200000             | \$0.80         | \$4.00          |
| Anthropic: Claude 3.5 Sonnet                               | blackboxai/anthropic/claude-3.5-sonnet                          | 200000             | \$3.00         | \$15.00         |
| Anthropic: Claude 3.5 Sonnet (2024-06-20)                  | blackboxai/anthropic/claude-3.5-sonnet-20240620                 | 200000             | \$3.00         | \$15.00         |
| Anthropic: Claude 3.5 Sonnet (2024-06-20) (self-moderated) | blackboxai/anthropic/claude-3.5-sonnet-20240620:beta            | 200000             | \$3.00         | \$15.00         |
| Anthropic: Claude 3.5 Sonnet (self-moderated)              | blackboxai/anthropic/claude-3.5-sonnet:beta                     | 200000             | \$3.00         | \$15.00         |
| Anthropic: Claude 3.7 Sonnet                               | blackboxai/anthropic/claude-3.7-sonnet                          | 200000             | \$3.00         | \$15.00         |
| Anthropic: Claude 3.7 Sonnet (self-moderated)              | blackboxai/anthropic/claude-3.7-sonnet:beta                     | 200000             | \$3.00         | \$15.00         |
| Anthropic: Claude 3.7 Sonnet (thinking)                    | blackboxai/anthropic/claude-3.7-sonnet:thinking                 | 200000             | \$3.00         | \$15.00         |
| Anthropic: Claude Opus 4                                   | blackboxai/anthropic/claude-opus-4                              | 200000             | \$15.00        | \$75.00         |
| Anthropic: Claude Sonnet 4                                 | blackboxai/anthropic/claude-sonnet-4                            | 200000             | \$3.00         | \$15.00         |
| Anthropic: Claude Sonnet 4.5                               | blackboxai/anthropic/claude-sonnet-4.5                          | 200000             | \$3.00         | \$15.00         |
| Anthropic: Claude v2                                       | blackboxai/anthropic/claude-2                                   | 200000             | \$8.00         | \$24.00         |
| Anthropic: Claude v2 (self-moderated)                      | blackboxai/anthropic/claude-2:beta                              | 200000             | \$8.00         | \$24.00         |
| Anthropic: Claude v2.0                                     | blackboxai/anthropic/claude-2.0                                 | 100000             | \$8.00         | \$24.00         |
| Anthropic: Claude v2.0 (self-moderated)                    | blackboxai/anthropic/claude-2.0:beta                            | 100000             | \$8.00         | \$24.00         |
| Anthropic: Claude v2.1                                     | blackboxai/anthropic/claude-2.1                                 | 200000             | \$8.00         | \$24.00         |
| Anthropic: Claude v2.1 (self-moderated)                    | blackboxai/anthropic/claude-2.1:beta                            | 200000             | \$8.00         | \$24.00         |
| Arcee AI: Arcee Blitz                                      | blackboxai/arcee-ai/arcee-blitz                                 | 32768              | \$0.45         | \$0.75          |
| BLACKBOX: Search                                           | blackboxai/blackbox-search                                      | 1048576            | \$0.20         | \$0.50          |
| Arcee AI: Caller Large                                     | blackboxai/arcee-ai/caller-large                                | 32768              | \$0.55         | \$0.85          |
| Arcee AI: Coder Large                                      | blackboxai/arcee-ai/coder-large                                 | 32768              | \$0.50         | \$0.80          |
| Arcee AI: Maestro Reasoning                                | blackboxai/arcee-ai/maestro-reasoning                           | 131072             | \$0.90         | \$3.30          |
| Arcee AI: Spotlight                                        | blackboxai/arcee-ai/spotlight                                   | 131072             | \$0.18         | \$0.18          |
| Arcee AI: Virtuoso Large                                   | blackboxai/arcee-ai/virtuoso-large                              | 131072             | \$0.75         | \$1.20          |
| Arcee AI: Virtuoso Medium V2                               | blackboxai/arcee-ai/virtuoso-medium-v2                          | 131072             | \$0.50         | \$0.80          |
| ArliAI: QwQ 32B RpR v1 (free)                              | blackboxai/arliai/qwq-32b-arliai-rpr-v1:free                    | 32768              | \$0.00         | \$0.00          |
| Auto Router                                                | blackboxai/openrouter/auto                                      | 2000000            | Variable       | Variable        |
| Baidu: ERNIE 4.5 300B A47B                                 | blackboxai/baidu/ernie-4.5-300b-a47b                            | 123000             | \$0.28         | \$1.10          |
| Cohere: Command                                            | blackboxai/cohere/command                                       | 4096               | \$1.00         | \$2.00          |
| Cohere: Command A                                          | blackboxai/cohere/command-a                                     | 256000             | \$2.50         | \$10.00         |
| Cohere: Command R                                          | blackboxai/cohere/command-r                                     | 128000             | \$0.50         | \$1.50          |
| Cohere: Command R (03-2024)                                | blackboxai/cohere/command-r-03-2024                             | 128000             | \$0.50         | \$1.50          |
| Cohere: Command R (08-2024)                                | blackboxai/cohere/command-r-08-2024                             | 128000             | \$0.15         | \$0.60          |
| Cohere: Command R+                                         | blackboxai/cohere/command-r-plus                                | 128000             | \$3.00         | \$15.00         |
| Cohere: Command R+ (04-2024)                               | blackboxai/cohere/command-r-plus-04-2024                        | 128000             | \$3.00         | \$15.00         |
| Cohere: Command R+ (08-2024)                               | blackboxai/cohere/command-r-plus-08-2024                        | 128000             | \$2.50         | \$10.00         |
| Cohere: Command R7B (12-2024)                              | blackboxai/cohere/command-r7b-12-2024                           | 128000             | \$0.04         | \$0.15          |
| Cypher Alpha (free)                                        | blackboxai/openrouter/cypher-alpha:free                         | 1000000            | \$0.00         | \$0.00          |
| DeepSeek: DeepSeek Prover V2                               | blackboxai/deepseek/deepseek-prover-v2                          | 131072             | \$0.50         | \$2.18          |
| DeepSeek: DeepSeek V3                                      | blackboxai/deepseek/deepseek-chat                               | 163840             | \$0.38         | \$0.89          |
| DeepSeek: DeepSeek V3 (free)                               | blackboxai/deepseek/deepseek-chat:free                          | 163840             | \$0.00         | \$0.00          |
| DeepSeek: DeepSeek V3 0324                                 | blackboxai/deepseek/deepseek-chat-v3-0324                       | 163840             | \$0.28         | \$0.88          |
| DeepSeek: DeepSeek V3 0324 (free)                          | blackboxai/deepseek/deepseek-chat-v3-0324:free                  | 16384              | \$0.00         | \$0.00          |
| DeepSeek: DeepSeek V3 Base (free)                          | blackboxai/deepseek/deepseek-v3-base:free                       | 163840             | \$0.00         | \$0.00          |
| DeepSeek: Deepseek R1 0528 Qwen3 8B                        | blackboxai/deepseek/deepseek-r1-0528-qwen3-8b                   | 32000              | \$0.01         | \$0.02          |
| DeepSeek: Deepseek R1 0528 Qwen3 8B (free)                 | blackboxai/deepseek/deepseek-r1-0528-qwen3-8b:free              | 131072             | \$0.00         | \$0.00          |
| DeepSeek: R1                                               | blackboxai/deepseek/deepseek-r1                                 | 128000             | \$0.45         | \$2.15          |
| DeepSeek: R1 (free)                                        | blackboxai/deepseek/deepseek-r1:free                            | 163840             | \$0.00         | \$0.00          |
| DeepSeek: R1 0528                                          | blackboxai/deepseek/deepseek-r1-0528                            | 128000             | \$0.50         | \$2.15          |
| DeepSeek: R1 0528 (free)                                   | blackboxai/deepseek/deepseek-r1-0528:free                       | 163840             | \$0.00         | \$0.00          |
| DeepSeek: R1 Distill Llama 70B                             | blackboxai/deepseek/deepseek-r1-distill-llama-70b               | 131072             | \$0.10         | \$0.40          |
| DeepSeek: R1 Distill Llama 70B (free)                      | blackboxai/deepseek/deepseek-r1-distill-llama-70b:free          | 8192               | \$0.00         | \$0.00          |
| DeepSeek: R1 Distill Llama 8B                              | blackboxai/deepseek/deepseek-r1-distill-llama-8b                | 32000              | \$0.04         | \$0.04          |
| DeepSeek: R1 Distill Qwen 1.5B                             | blackboxai/deepseek/deepseek-r1-distill-qwen-1.5b               | 131072             | \$0.18         | \$0.18          |
| DeepSeek: R1 Distill Qwen 14B                              | blackboxai/deepseek/deepseek-r1-distill-qwen-14b                | 64000              | \$0.15         | \$0.15          |
| DeepSeek: R1 Distill Qwen 14B (free)                       | blackboxai/deepseek/deepseek-r1-distill-qwen-14b:free           | 64000              | \$0.00         | \$0.00          |
| DeepSeek: R1 Distill Qwen 32B                              | blackboxai/deepseek/deepseek-r1-distill-qwen-32b                | 131072             | \$0.07         | \$0.15          |
| DeepSeek: R1 Distill Qwen 7B                               | blackboxai/deepseek/deepseek-r1-distill-qwen-7b                 | 131072             | \$0.10         | \$0.20          |
| Dolphin 2.9.2 Mixtral 8x22B                              | blackboxai/cognitivecomputations/dolphin-mixtral-8x22b          | 16000              | \$0.90         | \$0.90          |
| Dolphin3.0 Mistral 24B (free)                              | blackboxai/cognitivecomputations/dolphin3.0-mistral-24b:free    | 32768              | \$0.00         | \$0.00          |
| Dolphin3.0 R1 Mistral 24B (free)                           | blackboxai/cognitivecomputations/dolphin3.0-r1-mistral-24b:free | 32768              | \$0.00         | \$0.00          |
| EVA Llama 3.33 70B                                         | blackboxai/eva-unit-01/eva-llama-3.33-70b                       | 16384              | \$4.00         | \$6.00          |
| EVA Qwen2.5 32B                                            | blackboxai/eva-unit-01/eva-qwen-2.5-32b                         | 16384              | \$2.60         | \$3.40          |
| EVA Qwen2.5 72B                                            | blackboxai/eva-unit-01/eva-qwen-2.5-72b                         | 16384              | \$4.00         | \$6.00          |
| EleutherAI: Llemma 7b                                      | blackboxai/eleutherai/llemma\_7b                                | 4096               | \$0.80         | \$1.20          |
| Fimbulvetr 11B v2                                          | blackboxai/sao10k/fimbulvetr-11b-v2                             | 4096               | \$0.80         | \$1.20          |
| Goliath 120B                                               | blackboxai/alpindale/goliath-120b                               | 6144               | \$9.00         | \$11.00         |
| Google: Gemini 1.5 Flash                                   | blackboxai/google/gemini-flash-1.5                              | 1000000            | \$0.07         | \$0.30          |
| Google: Gemini 1.5 Flash 8B                                | blackboxai/google/gemini-flash-1.5-8b                           | 1000000            | \$0.04         | \$0.15          |
| Google: Gemini 1.5 Pro                                     | blackboxai/google/gemini-pro-1.5                                | 2000000            | \$1.25         | \$5.00          |
| Google: Gemini 2.0 Flash                                   | blackboxai/google/gemini-2.0-flash-001                          | 1048576            | \$0.10         | \$0.40          |
| Google: Gemini 2.0 Flash Experimental (free)               | blackboxai/google/gemini-2.0-flash-exp:free                     | 1048576            | \$0.00         | \$0.00          |
| Google: Gemini 2.0 Flash Lite                              | blackboxai/google/gemini-2.0-flash-lite-001                     | 1048576            | \$0.07         | \$0.30          |
| Google: Gemini 2.5 Flash                                   | blackboxai/google/gemini-2.5-flash                              | 1048576            | \$0.30         | \$2.50          |
| Google: Gemini 2.5 Flash Lite Preview 06-17                | blackboxai/google/gemini-2.5-flash-lite-preview-06-17           | 1048576            | \$0.10         | \$0.40          |
| Google: Gemini 2.5 Flash Preview 04-17                     | blackboxai/google/gemini-2.5-flash-preview                      | 1048576            | \$0.15         | \$0.60          |
| Google: Gemini 2.5 Flash Preview 04-17 (thinking)          | blackboxai/google/gemini-2.5-flash-preview:thinking             | 1048576            | \$0.15         | \$3.50          |
| Google: Gemini 2.5 Flash Preview 05-20                     | blackboxai/google/gemini-2.5-flash-preview-05-20                | 1048576            | \$0.15         | \$0.60          |
| Google: Gemini 2.5 Flash Preview 05-20 (thinking)          | blackboxai/google/gemini-2.5-flash-preview-05-20:thinking       | 1048576            | \$0.15         | \$3.50          |
| Google: Gemini 2.5 Pro                                     | blackboxai/google/gemini-2.5-pro                                | 1048576            | \$1.25         | \$10.00         |
| Google: Gemini 2.5 Pro Experimental                        | blackboxai/google/gemini-2.5-pro-exp-03-25                      | 1048576            | \$0.00         | \$0.00          |
| Google: Gemini 2.5 Pro Preview 05-06                       | blackboxai/google/gemini-2.5-pro-preview-05-06                  | 1048576            | \$1.25         | \$10.00         |
| Google: Gemini 2.5 Pro Preview 06-05                       | blackboxai/google/gemini-2.5-pro-preview                        | 1048576            | \$1.25         | \$10.00         |
| Google: Gemini 3 Pro Preview                               | blackboxai/google/gemini-3-pro-preview                          | 1048576            | \$2.00         | \$12.00         |
| Google: Gemma 2 27B                                        | blackboxai/google/gemma-2-27b-it                                | 8192               | \$0.80         | \$0.80          |
| Google: Gemma 2 9B                                         | blackboxai/google/gemma-2-9b-it                                 | 8192               | \$0.20         | \$0.20          |
| Google: Gemma 2 9B (free)                                  | blackboxai/google/gemma-2-9b-it:free                            | 8192               | \$0.00         | \$0.00          |
| Google: Gemma 3 12B                                        | blackboxai/google/gemma-3-12b-it                                | 131072             | \$0.05         | \$0.10          |
| Google: Gemma 3 12B (free)                                 | blackboxai/google/gemma-3-12b-it:free                           | 96000              | \$0.00         | \$0.00          |
| Google: Gemma 3 27B                                        | blackboxai/google/gemma-3-27b-it                                | 131072             | \$0.09         | \$0.17          |
| Google: Gemma 3 27B (free)                                 | blackboxai/google/gemma-3-27b-it:free                           | 96000              | \$0.00         | \$0.00          |
| Google: Gemma 3 4B                                         | blackboxai/google/gemma-3-4b-it                                 | 131072             | \$0.02         | \$0.04          |
| Google: Gemma 3 4B (free)                                  | blackboxai/google/gemma-3-4b-it:free                            | 32768              | \$0.00         | \$0.00          |
| Google: Gemma 3n 4B                                        | blackboxai/google/gemma-3n-e4b-it                               | 32768              | \$0.02         | \$0.04          |
| Google: Gemma 3n 4B (free)                                 | blackboxai/google/gemma-3n-e4b-it:free                          | 8192               | \$0.00         | \$0.00          |
| Inception: Mercury                                         | blackboxai/inception/mercury                                    | 32000              | \$0.25         | \$1.00          |
| Inception: Mercury Coder                                   | blackboxai/inception/mercury-coder                              | 32000              | \$0.25         | \$1.00          |
| Infermatic: Mistral Nemo Inferor 12B                       | blackboxai/infermatic/mn-inferor-12b                            | 16384              | \$0.80         | \$1.20          |
| Inflection: Inflection 3 Pi                                | blackboxai/inflection/inflection-3-pi                           | 8000               | \$2.50         | \$10.00         |
| Inflection: Inflection 3 Productivity                      | blackboxai/inflection/inflection-3-productivity                 | 8000               | \$2.50         | \$10.00         |
| Kimi Dev 72b (free)                                        | blackboxai/moonshotai/kimi-dev-72b:free                         | 131072             | \$0.00         | \$0.00          |
| Liquid: LFM 3B                                             | blackboxai/liquid/lfm-3b                                        | 32768              | \$0.02         | \$0.02          |
| Liquid: LFM 40B MoE                                        | blackboxai/liquid/lfm-40b                                       | 32768              | \$0.15         | \$0.15          |
| Liquid: LFM 7B                                             | blackboxai/liquid/lfm-7b                                        | 32768              | \$0.01         | \$0.01          |
| Llama Guard 3 8B                                           | blackboxai/meta-llama/llama-guard-3-8b                          | 131072             | \$0.02         | \$0.06          |
| Magnum 72B                                                 | blackboxai/alpindale/magnum-72b                                 | 16384              | \$4.00         | \$6.00          |
| Magnum v2 72B                                              | blackboxai/anthracite-org/magnum-v2-72b                         | 32768              | \$3.00         | \$3.00          |
| Magnum v4 72B                                              | blackboxai/anthracite-org/magnum-v4-72b                         | 16384              | \$2.50         | \$3.00          |
| Mancer: Weaver (alpha)                                     | blackboxai/mancer/weaver                                        | 8000               | \$1.50         | \$1.50          |
| Meta: Llama 3 70B Instruct                                 | blackboxai/meta-llama/llama-3-70b-instruct                      | 8192               | \$0.30         | \$0.40          |
| Meta: Llama 3 8B Instruct                                  | blackboxai/meta-llama/llama-3-8b-instruct                       | 8192               | \$0.03         | \$0.06          |
| Meta: Llama 3.1 405B (base)                                | blackboxai/meta-llama/llama-3.1-405b                            | 32768              | \$2.00         | \$2.00          |
| Meta: Llama 3.1 405B Instruct                              | blackboxai/meta-llama/llama-3.1-405b-instruct                   | 32768              | \$0.80         | \$0.80          |
| Meta: Llama 3.1 70B Instruct                               | blackboxai/meta-llama/llama-3.1-70b-instruct                    | 131072             | \$0.10         | \$0.28          |
| Meta: Llama 3.1 8B Instruct                                | blackboxai/meta-llama/llama-3.1-8b-instruct                     | 131000             | \$0.02         | \$0.02          |
| Meta: Llama 3.2 11B Vision Instruct                        | blackboxai/meta-llama/llama-3.2-11b-vision-instruct             | 131072             | \$0.05         | \$0.05          |
| Meta: Llama 3.2 11B Vision Instruct (free)                 | blackboxai/meta-llama/llama-3.2-11b-vision-instruct:free        | 131072             | \$0.00         | \$0.00          |
| Meta: Llama 3.2 1B Instruct                                | blackboxai/meta-llama/llama-3.2-1b-instruct                     | 131072             | \$0.01         | \$0.01          |
| Meta: Llama 3.2 3B Instruct                                | blackboxai/meta-llama/llama-3.2-3b-instruct                     | 20000              | \$0.00         | \$0.01          |
| Meta: Llama 3.2 90B Vision Instruct                        | blackboxai/meta-llama/llama-3.2-90b-vision-instruct             | 131072             | \$1.20         | \$1.20          |
| Meta: Llama 3.3 70B Instruct                               | blackboxai/meta-llama/llama-3.3-70b-instruct                    | 131072             | \$0.04         | \$0.12          |
| Meta: Llama 3.3 70B Instruct (free)                        | blackboxai/meta-llama/llama-3.3-70b-instruct:free               | 131072             | \$0.00         | \$0.00          |
| Meta: Llama 4 Maverick                                     | blackboxai/meta-llama/llama-4-maverick                          | 1048576            | \$0.15         | \$0.60          |
| Meta: Llama 4 Maverick (free)                              | blackboxai/meta-llama/llama-4-maverick:free                     | 128000             | \$0.00         | \$0.00          |
| Meta: Llama 4 Scout                                        | blackboxai/meta-llama/llama-4-scout                             | 1048576            | \$0.08         | \$0.30          |
| Meta: Llama 4 Scout (free)                                 | blackboxai/meta-llama/llama-4-scout:free                        | 64000              | \$0.00         | \$0.00          |
| Meta: Llama Guard 4 12B                                    | blackboxai/meta-llama/llama-guard-4-12b                         | 163840             | \$0.05         | \$0.05          |
| Meta: LlamaGuard 2 8B                                      | blackboxai/meta-llama/llama-guard-2-8b                          | 8192               | \$0.20         | \$0.20          |
| Microsoft: MAI DS R1 (free)                                | blackboxai/microsoft/mai-ds-r1:free                             | 163840             | \$0.00         | \$0.00          |
| Microsoft: Phi 4                                           | blackboxai/microsoft/phi-4                                      | 16384              | \$0.07         | \$0.14          |
| Microsoft: Phi 4 Multimodal Instruct                       | blackboxai/microsoft/phi-4-multimodal-instruct                  | 131072             | \$0.05         | \$0.10          |
| Microsoft: Phi 4 Reasoning Plus                            | blackboxai/microsoft/phi-4-reasoning-plus                       | 32768              | \$0.07         | \$0.35          |
| Microsoft: Phi-3 Medium 128K Instruct                      | blackboxai/microsoft/phi-3-medium-128k-instruct                 | 128000             | \$1.00         | \$1.00          |
| Microsoft: Phi-3 Mini 128K Instruct                        | blackboxai/microsoft/phi-3-mini-128k-instruct                   | 128000             | \$0.10         | \$0.10          |
| Microsoft: Phi-3.5 Mini 128K Instruct                      | blackboxai/microsoft/phi-3.5-mini-128k-instruct                 | 128000             | \$0.10         | \$0.10          |
| Midnight Rose 70B                                          | blackboxai/sophosympatheia/midnight-rose-70b                    | 4096               | \$0.80         | \$0.80          |
| MiniMax: MiniMax M1                                        | blackboxai/minimax/minimax-m1                                   | 1000000            | \$0.30         | \$1.65          |
| MiniMax: MiniMax M2                                        | blackboxai/minimax/minimax-m2                                   | 204800             | \$0.26         | \$1.02          |
| MiniMax: MiniMax-01                                        | blackboxai/minimax/minimax-01                                   | 1000192            | \$0.20         | \$1.10          |
| Mistral Large                                              | blackboxai/mistralai/mistral-large                              | 128000             | \$2.00         | \$6.00          |
| Mistral Large 2407                                         | blackboxai/mistralai/mistral-large-2407                         | 131072             | \$2.00         | \$6.00          |
| Mistral Large 2411                                         | blackboxai/mistralai/mistral-large-2411                         | 131072             | \$2.00         | \$6.00          |
| Mistral Nemo 12B Celeste                                   | blackboxai/nothingiisreal/mn-celeste-12b                        | 16384              | \$0.80         | \$1.20          |
| Mistral Small                                              | blackboxai/mistralai/mistral-small                              | 32768              | \$0.20         | \$0.60          |
| Mistral Tiny                                               | blackboxai/mistralai/mistral-tiny                               | 32768              | \$0.25         | \$0.25          |
| Mistral: Codestral 2501                                    | blackboxai/mistralai/codestral-2501                             | 262144             | \$0.30         | \$0.90          |
| Mistral: Devstral Small                                    | blackboxai/mistralai/devstral-small                             | 128000             | \$0.06         | \$0.12          |
| Mistral: Devstral Small (free)                             | blackboxai/mistralai/devstral-small:free                        | 32768              | \$0.00         | \$0.00          |
| Mistral: Magistral Medium 2506                             | blackboxai/mistralai/magistral-medium-2506                      | 40960              | \$2.00         | \$5.00          |
| Mistral: Magistral Medium 2506 (thinking)                  | blackboxai/mistralai/magistral-medium-2506:thinking             | 40960              | \$2.00         | \$5.00          |
| Mistral: Magistral Small 2506                              | blackboxai/mistralai/magistral-small-2506                       | 40000              | \$0.50         | \$1.50          |
| Mistral: Ministral 3B                                      | blackboxai/mistralai/ministral-3b                               | 131072             | \$0.04         | \$0.04          |
| Mistral: Ministral 8B                                      | blackboxai/mistralai/ministral-8b                               | 128000             | \$0.10         | \$0.10          |
| Mistral: Mistral 7B Instruct                               | blackboxai/mistralai/mistral-7b-instruct                        | 32768              | \$0.03         | \$0.05          |
| Mistral: Mistral 7B Instruct (free)                        | blackboxai/mistralai/mistral-7b-instruct:free                   | 32768              | \$0.00         | \$0.00          |
| Mistral: Mistral 7B Instruct v0.1                          | blackboxai/mistralai/mistral-7b-instruct-v0.1                   | 2824               | \$0.11         | \$0.19          |
| Mistral: Mistral 7B Instruct v0.2                          | blackboxai/mistralai/mistral-7b-instruct-v0.2                   | 32768              | \$0.20         | \$0.20          |
| Mistral: Mistral 7B Instruct v0.3                          | blackboxai/mistralai/mistral-7b-instruct-v0.3                   | 32768              | \$0.03         | \$0.05          |
| Mistral: Mistral Medium 3                                  | blackboxai/mistralai/mistral-medium-3                           | 131072             | \$0.40         | \$2.00          |
| Mistral: Mistral Nemo                                      | blackboxai/mistralai/mistral-nemo                               | 131072             | \$0.01         | \$0.00          |
| Mistral: Mistral Nemo (free)                               | blackboxai/mistralai/mistral-nemo:free                          | 131072             | \$0.00         | \$0.00          |
| Mistral: Mistral Small 3                                   | blackboxai/mistralai/mistral-small-24b-instruct-2501            | 32768              | \$0.05         | \$0.09          |
| Mistral: Mistral Small 3 (free)                            | blackboxai/mistralai/mistral-small-24b-instruct-2501:free       | 32768              | \$0.00         | \$0.00          |
| Mistral: Mistral Small 3.1 24B                             | blackboxai/mistralai/mistral-small-3.1-24b-instruct             | 128000             | \$0.05         | \$0.10          |
| Mistral: Mistral Small 3.1 24B (free)                      | blackboxai/mistralai/mistral-small-3.1-24b-instruct:free        | 96000              | \$0.00         | \$0.00          |
| Mistral: Mistral Small 3.2 24B                             | blackboxai/mistralai/mistral-small-3.2-24b-instruct             | 128000             | \$0.05         | \$0.10          |
| Mistral: Mistral Small 3.2 24B (free)                      | blackboxai/mistralai/mistral-small-3.2-24b-instruct:free        | 96000              | \$0.00         | \$0.00          |
| Mistral: Mixtral 8x22B Instruct                            | blackboxai/mistralai/mixtral-8x22b-instruct                     | 65536              | \$0.90         | \$0.90          |
| Mistral: Mixtral 8x7B Instruct                             | blackboxai/mistralai/mixtral-8x7b-instruct                      | 32768              | \$0.08         | \$0.24          |
| Mistral: Pixtral 12B                                       | blackboxai/mistralai/pixtral-12b                                | 32768              | \$0.10         | \$0.10          |
| Mistral: Pixtral Large 2411                                | blackboxai/mistralai/pixtral-large-2411                         | 131072             | \$2.00         | \$6.00          |
| Mistral: Saba                                              | blackboxai/mistralai/mistral-saba                               | 32768              | \$0.20         | \$0.60          |
| Moonshot AI: Kimi VL A3B Thinking (free)                   | blackboxai/moonshotai/kimi-vl-a3b-thinking:free                 | 131072             | \$0.00         | \$0.00          |
| Morph: Fast Apply                                          | blackboxai/morph/morph-v2                                       | 32000              | \$1.20         | \$2.70          |
| MythoMax 13B                                               | blackboxai/gryphe/mythomax-l2-13b                               | 4096               | \$0.07         | \$0.07          |
| NVIDIA: Llama 3.1 Nemotron 70B Instruct                    | blackboxai/nvidia/llama-3.1-nemotron-70b-instruct               | 131072             | \$0.12         | \$0.30          |
| NVIDIA: Llama 3.1 Nemotron Ultra 253B v1                   | blackboxai/nvidia/llama-3.1-nemotron-ultra-253b-v1              | 131072             | \$0.60         | \$1.80          |
| NVIDIA: Llama 3.1 Nemotron Ultra 253B v1 (free)            | blackboxai/nvidia/llama-3.1-nemotron-ultra-253b-v1:free         | 131072             | \$0.00         | \$0.00          |
| NVIDIA: Llama 3.3 Nemotron Super 49B v1                    | blackboxai/nvidia/llama-3.3-nemotron-super-49b-v1               | 131072             | \$0.13         | \$0.40          |
| NVIDIA: Llama 3.3 Nemotron Super 49B v1 (free)             | blackboxai/nvidia/llama-3.3-nemotron-super-49b-v1:free          | 131072             | \$0.00         | \$0.00          |
| NeverSleep: Llama 3 Lumimaid 70B                           | blackboxai/neversleep/llama-3-lumimaid-70b                      | 8192               | \$4.00         | \$6.00          |
| NeverSleep: Llama 3 Lumimaid 8B                            | blackboxai/neversleep/llama-3-lumimaid-8b                       | 24576              | \$0.20         | \$1.25          |
| NeverSleep: Lumimaid v0.2 70B                              | blackboxai/neversleep/llama-3.1-lumimaid-70b                    | 16384              | \$2.50         | \$3.00          |
| NeverSleep: Lumimaid v0.2 8B                               | blackboxai/neversleep/llama-3.1-lumimaid-8b                     | 32768              | \$0.20         | \$1.25          |
| Noromaid 20B                                               | blackboxai/neversleep/noromaid-20b                              | 8192               | \$1.25         | \$2.00          |
| Nous: DeepHermes 3 Llama 3 8B Preview (free)               | blackboxai/nousresearch/deephermes-3-llama-3-8b-preview:free    | 131072             | \$0.00         | \$0.00          |
| Nous: Hermes 2 Mixtral 8x7B DPO                            | blackboxai/nousresearch/nous-hermes-2-mixtral-8x7b-dpo          | 32768              | \$0.60         | \$0.60          |
| Nous: Hermes 3 405B Instruct                               | blackboxai/nousresearch/hermes-3-llama-3.1-405b                 | 131072             | \$0.70         | \$0.80          |
| Nous: Hermes 3 70B Instruct                                | blackboxai/nousresearch/hermes-3-llama-3.1-70b                  | 131072             | \$0.10         | \$0.28          |
| NousResearch: Hermes 2 Pro - Llama-3 8B                    | blackboxai/nousresearch/hermes-2-pro-llama-3-8b                 | 131072             | \$0.02         | \$0.04          |
| OpenAI: ChatGPT-4o                                         | blackboxai/openai/chatgpt-4o-latest                             | 128000             | \$5.00         | \$15.00         |
| OpenAI: Codex Mini                                         | blackboxai/openai/codex-mini                                    | 200000             | \$1.50         | \$6.00          |
| OpenAI: GPT-3.5 Turbo (older v0613)                        | blackboxai/openai/gpt-3.5-turbo-0613                            | 4095               | \$1.00         | \$2.00          |
| OpenAI: GPT-3.5 Turbo 16k                                  | blackboxai/openai/gpt-3.5-turbo-16k                             | 16385              | \$3.00         | \$4.00          |
| OpenAI: GPT-3.5 Turbo Instruct                             | blackboxai/openai/gpt-3.5-turbo-instruct                        | 4095               | \$1.50         | \$2.00          |
| OpenAI: GPT-4                                              | blackboxai/openai/gpt-4                                         | 8191               | \$30.00        | \$60.00         |
| OpenAI: GPT-4 (older v0314)                                | blackboxai/openai/gpt-4-0314                                    | 8191               | \$30.00        | \$60.00         |
| OpenAI: GPT-4 Turbo                                        | blackboxai/openai/gpt-4-turbo                                   | 128000             | \$10.00        | \$30.00         |
| OpenAI: GPT-4 Turbo (older v1106)                          | blackboxai/openai/gpt-4-1106-preview                            | 128000             | \$10.00        | \$30.00         |
| OpenAI: GPT-4 Turbo Preview                                | blackboxai/openai/gpt-4-turbo-preview                           | 128000             | \$10.00        | \$30.00         |
| OpenAI: GPT-4.1                                            | blackboxai/openai/gpt-4.1                                       | 1047576            | \$2.00         | \$8.00          |
| OpenAI: GPT-4.1 Mini                                       | blackboxai/openai/gpt-4.1-mini                                  | 1047576            | \$0.40         | \$1.60          |
| OpenAI: GPT-4.1 Nano                                       | blackboxai/openai/gpt-4.1-nano                                  | 1047576            | \$0.10         | \$0.40          |
| OpenAI: GPT-4.5 (Preview)                                  | blackboxai/openai/gpt-4.5-preview                               | 128000             | \$75.00        | \$150.00        |
| OpenAI: GPT-4o                                             | blackboxai/openai/gpt-4o                                        | 128000             | \$2.50         | \$10.00         |
| OpenAI: GPT-4o (2024-05-13)                                | blackboxai/openai/gpt-4o-2024-05-13                             | 128000             | \$5.00         | \$15.00         |
| OpenAI: GPT-4o (2024-08-06)                                | blackboxai/openai/gpt-4o-2024-08-06                             | 128000             | \$2.50         | \$10.00         |
| OpenAI: GPT-4o (2024-11-20)                                | blackboxai/openai/gpt-4o-2024-11-20                             | 128000             | \$2.50         | \$10.00         |
| OpenAI: GPT-4o (extended)                                  | blackboxai/openai/gpt-4o:extended                               | 128000             | \$6.00         | \$18.00         |
| OpenAI: GPT-4o Search Preview                              | blackboxai/openai/gpt-4o-search-preview                         | 128000             | \$2.50         | \$10.00         |
| OpenAI: GPT-4o-mini                                        | blackboxai/openai/gpt-4o-mini                                   | 128000             | \$0.15         | \$0.60          |
| OpenAI: GPT-4o-mini (2024-07-18)                           | blackboxai/openai/gpt-4o-mini-2024-07-18                        | 128000             | \$0.15         | \$0.60          |
| OpenAI: GPT-4o-mini Search Preview                         | blackboxai/openai/gpt-4o-mini-search-preview                    | 128000             | \$0.15         | \$0.60          |
| OpenAI: GPT-5.1                                            | blackboxai/openai/gpt-5.1                                       | 400000             | \$1.25         | \$10.00         |
| OpenAI: GPT-5.1-Codex                                      | blackboxai/openai/gpt-5.1-codex                                 | 400000             | \$1.25         | \$10.00         |
| OpenAI: o1                                                 | blackboxai/openai/o1                                            | 200000             | \$15.00        | \$60.00         |
| OpenAI: o1-mini                                            | blackboxai/openai/o1-mini                                       | 128000             | \$1.10         | \$4.40          |
| OpenAI: o1-mini (2024-09-12)                               | blackboxai/openai/o1-mini-2024-09-12                            | 128000             | \$1.10         | \$4.40          |
| OpenAI: o1-preview                                         | blackboxai/openai/o1-preview                                    | 128000             | \$15.00        | \$60.00         |
| OpenAI: o1-preview (2024-09-12)                            | blackboxai/openai/o1-preview-2024-09-12                         | 128000             | \$15.00        | \$60.00         |
| OpenAI: o1-pro                                             | blackboxai/openai/o1-pro                                        | 200000             | \$150.00       | \$600.00        |
| OpenAI: o3                                                 | blackboxai/openai/o3                                            | 200000             | \$2.00         | \$8.00          |
| OpenAI: o3 Mini                                            | blackboxai/openai/o3-mini                                       | 200000             | \$1.10         | \$4.40          |
| OpenAI: o3 Mini High                                       | blackboxai/openai/o3-mini-high                                  | 200000             | \$1.10         | \$4.40          |
| OpenAI: o3 Pro                                             | blackboxai/openai/o3-pro                                        | 200000             | \$20.00        | \$80.00         |
| OpenAI: o4 Mini                                            | blackboxai/openai/o4-mini                                       | 200000             | \$1.10         | \$4.40          |
| OpenAI: o4 Mini High                                       | blackboxai/openai/o4-mini-high                                  | 200000             | \$1.10         | \$4.40          |
| OpenGVLab: InternVL3 14B                                   | blackboxai/opengvlab/internvl3-14b                              | 12288              | \$0.20         | \$0.40          |
| OpenGVLab: InternVL3 2B                                    | blackboxai/opengvlab/internvl3-2b                               | 12288              | \$0.05         | \$0.10          |
| OpenHands LM 32B V0.1                                      | blackboxai/all-hands/openhands-lm-32b-v0.1                      | 16384              | \$2.60         | \$3.40          |
| Perplexity: Llama 3.1 Sonar 70B Online                     | blackboxai/perplexity/llama-3.1-sonar-large-128k-online         | 127072             | \$1.00         | \$1.00          |
| Perplexity: Llama 3.1 Sonar 8B Online                      | blackboxai/perplexity/llama-3.1-sonar-small-128k-online         | 127072             | \$0.20         | \$0.20          |
| Perplexity: R1 1776                                        | blackboxai/perplexity/r1-1776                                   | 128000             | \$2.00         | \$8.00          |
| Perplexity: Sonar                                          | blackboxai/perplexity/sonar                                     | 127072             | \$1.00         | \$1.00          |
| Perplexity: Sonar Deep Research                            | blackboxai/perplexity/sonar-deep-research                       | 128000             | \$2.00         | \$8.00          |
| Perplexity: Sonar Pro                                      | blackboxai/perplexity/sonar-pro                                 | 200000             | \$3.00         | \$15.00         |
| Perplexity: Sonar Reasoning                                | blackboxai/perplexity/sonar-reasoning                           | 127000             | \$1.00         | \$5.00          |
| Perplexity: Sonar Reasoning Pro                            | blackboxai/perplexity/sonar-reasoning-pro                       | 128000             | \$2.00         | \$8.00          |
| Pygmalion: Mythalion 13B                                   | blackboxai/pygmalionai/mythalion-13b                            | 4096               | \$0.80         | \$1.20          |
| Qwen 2 72B Instruct                                        | blackboxai/qwen/qwen-2-72b-instruct                             | 32768              | \$0.90         | \$0.90          |
| Qwen2.5 72B Instruct                                       | blackboxai/qwen/qwen-2.5-72b-instruct                           | 32768              | \$0.12         | \$0.39          |
| Qwen2.5 72B Instruct (free)                                | blackboxai/qwen/qwen-2.5-72b-instruct:free                      | 32768              | \$0.00         | \$0.00          |
| Qwen2.5 7B Instruct                                        | blackboxai/qwen/qwen-2.5-7b-instruct                            | 32768              | \$0.04         | \$0.10          |
| Qwen2.5 Coder 32B Instruct                                 | blackboxai/qwen/qwen-2.5-coder-32b-instruct                     | 32768              | \$0.06         | \$0.15          |
| Qwen2.5 Coder 32B Instruct (free)                          | blackboxai/qwen/qwen-2.5-coder-32b-instruct:free                | 32768              | \$0.00         | \$0.00          |
| Qwen: QwQ 32B                                              | blackboxai/qwen/qwq-32b                                         | 131072             | \$0.07         | \$0.15          |
| Qwen: QwQ 32B (free)                                       | blackboxai/qwen/qwq-32b:free                                    | 131072             | \$0.00         | \$0.00          |
| Qwen: QwQ 32B Preview                                      | blackboxai/qwen/qwq-32b-preview                                 | 32768              | \$0.20         | \$0.20          |
| Qwen: Qwen VL Max                                          | blackboxai/qwen/qwen-vl-max                                     | 7500               | \$0.80         | \$3.20          |
| Qwen: Qwen VL Plus                                         | blackboxai/qwen/qwen-vl-plus                                    | 7500               | \$0.21         | \$0.63          |
| Qwen: Qwen-Max                                             | blackboxai/qwen/qwen-max                                        | 32768              | \$1.60         | \$6.40          |
| Qwen: Qwen-Plus                                            | blackboxai/qwen/qwen-plus                                       | 131072             | \$0.40         | \$1.20          |
| Qwen: Qwen-Turbo                                           | blackboxai/qwen/qwen-turbo                                      | 1000000            | \$0.05         | \$0.20          |
| Qwen: Qwen2.5 VL 32B Instruct                              | blackboxai/qwen/qwen2.5-vl-32b-instruct                         | 128000             | \$0.90         | \$0.90          |
| Qwen: Qwen2.5 VL 32B Instruct (free)                       | blackboxai/qwen/qwen2.5-vl-32b-instruct:free                    | 8192               | \$0.00         | \$0.00          |
| Qwen: Qwen2.5 VL 72B Instruct                              | blackboxai/qwen/qwen2.5-vl-72b-instruct                         | 32000              | \$0.25         | \$0.75          |
| Qwen: Qwen2.5 VL 72B Instruct (free)                       | blackboxai/qwen/qwen2.5-vl-72b-instruct:free                    | 131072             | \$0.00         | \$0.00          |
| Qwen: Qwen2.5-VL 7B Instruct                               | blackboxai/qwen/qwen-2.5-vl-7b-instruct                         | 32768              | \$0.20         | \$0.20          |
| Qwen: Qwen3 14B                                            | blackboxai/qwen/qwen3-14b                                       | 40960              | \$0.06         | \$0.24          |
| Qwen: Qwen3 14B (free)                                     | blackboxai/qwen/qwen3-14b:free                                  | 40960              | \$0.00         | \$0.00          |
| Qwen: Qwen3 235B A22B                                      | blackboxai/qwen/qwen3-235b-a22b                                 | 40960              | \$0.13         | \$0.60          |
| Qwen: Qwen3 235B A22B (free)                               | blackboxai/qwen/qwen3-235b-a22b:free                            | 40960              | \$0.00         | \$0.00          |
| Qwen: Qwen3 30B A3B                                        | blackboxai/qwen/qwen3-30b-a3b                                   | 40960              | \$0.08         | \$0.29          |
| Qwen: Qwen3 30B A3B (free)                                 | blackboxai/qwen/qwen3-30b-a3b:free                              | 40960              | \$0.00         | \$0.00          |
| Qwen: Qwen3 32B                                            | blackboxai/qwen/qwen3-32b                                       | 40960              | \$0.10         | \$0.30          |
| Qwen: Qwen3 32B (free)                                     | blackboxai/qwen/qwen3-32b:free                                  | 40960              | \$0.00         | \$0.00          |
| Qwen: Qwen3 8B                                             | blackboxai/qwen/qwen3-8b                                        | 128000             | \$0.04         | \$0.14          |
| Qwen: Qwen3 8B (free)                                      | blackboxai/qwen/qwen3-8b:free                                   | 40960              | \$0.00         | \$0.00          |
| Qwerky 72B (free)                                          | blackboxai/featherless/qwerky-72b:free                          | 32768              | \$0.00         | \$0.00          |
| ReMM SLERP 13B                                             | blackboxai/undi95/remm-slerp-l2-13b                             | 4096               | \$0.80         | \$1.20          |
| Reka: Flash 3 (free)                                       | blackboxai/rekaai/reka-flash-3:free                             | 32768              | \$0.00         | \$0.00          |
| Sao10K: Llama 3 8B Lunaris                                 | blackboxai/sao10k/l3-lunaris-8b                                 | 8192               | \$0.02         | \$0.05          |
| Sao10K: Llama 3.1 Euryale 70B v2.2                         | blackboxai/sao10k/l3.1-euryale-70b                              | 32768              | \$0.65         | \$0.75          |
| Sao10K: Llama 3.3 Euryale 70B                              | blackboxai/sao10k/l3.3-euryale-70b                              | 131072             | \$0.65         | \$0.75          |
| Sao10k: Llama 3 Euryale 70B v2.1                           | blackboxai/sao10k/l3-euryale-70b                                | 8192               | \$1.48         | \$1.48          |
| Sarvam AI: Sarvam-M (free)                                 | blackboxai/sarvamai/sarvam-m:free                               | 32768              | \$0.00         | \$0.00          |
| Shisa AI: Shisa V2 Llama 3.3 70B  (free)                   | blackboxai/shisa-ai/shisa-v2-llama3.3-70b:free                  | 32768              | \$0.00         | \$0.00          |
| SorcererLM 8x22B                                           | blackboxai/raifle/sorcererlm-8x22b                              | 16000              | \$4.50         | \$4.50          |
| THUDM: GLM 4 32B                                           | blackboxai/thudm/glm-4-32b                                      | 32000              | \$0.24         | \$0.24          |
| THUDM: GLM 4 32B (free)                                    | blackboxai/thudm/glm-4-32b:free                                 | 32768              | \$0.00         | \$0.00          |
| THUDM: GLM Z1 32B                                          | blackboxai/thudm/glm-z1-32b                                     | 32000              | \$0.24         | \$0.24          |
| THUDM: GLM Z1 32B (free)                                   | blackboxai/thudm/glm-z1-32b:free                                | 32768              | \$0.00         | \$0.00          |
| THUDM: GLM Z1 Rumination 32B                               | blackboxai/thudm/glm-z1-rumination-32b                          | 32000              | \$0.24         | \$0.24          |
| TNG: DeepSeek R1T Chimera (free)                           | blackboxai/tngtech/deepseek-r1t-chimera:free                    | 163840             | \$0.00         | \$0.00          |
| TheDrummer: Anubis 70B V1.1                                | blackboxai/thedrummer/anubis-70b-v1.1                           | 131072             | \$0.30         | \$0.80          |
| TheDrummer: Anubis Pro 105B V1                             | blackboxai/thedrummer/anubis-pro-105b-v1                        | 131072             | \$0.80         | \$1.00          |
| TheDrummer: Rocinante 12B                                  | blackboxai/thedrummer/rocinante-12b                             | 32768              | \$0.20         | \$0.50          |
| TheDrummer: Skyfall 36B V2                                 | blackboxai/thedrummer/skyfall-36b-v2                            | 32768              | \$0.50         | \$0.80          |
| TheDrummer: UnslopNemo 12B                                 | blackboxai/thedrummer/unslopnemo-12b                            | 32768              | \$0.40         | \$0.40          |
| TheDrummer: Valkyrie 49B V1                                | blackboxai/thedrummer/valkyrie-49b-v1                           | 131072             | \$0.50         | \$0.80          |
| Toppy M 7B                                                 | blackboxai/undi95/toppy-m-7b                                    | 4096               | \$0.80         | \$1.20          |
| Typhoon2 70B Instruct                                      | blackboxai/scb10x/llama3.1-typhoon2-70b-instruct                | 8192               | \$0.88         | \$0.88          |
| WizardLM-2 8x22B                                           | blackboxai/microsoft/wizardlm-2-8x22b                           | 65536              | \$0.48         | \$0.48          |
| xAI: Grok 2 1212                                           | blackboxai/x-ai/grok-2-1212                                     | 131072             | \$2.00         | \$10.00         |
| xAI: Grok 2 Vision 1212                                    | blackboxai/x-ai/grok-2-vision-1212                              | 32768              | \$2.00         | \$10.00         |
| xAI: Grok 3                                                | blackboxai/x-ai/grok-3                                          | 131072             | \$3.00         | \$15.00         |
| xAI: Grok 3 Beta                                           | blackboxai/x-ai/grok-3-beta                                     | 131072             | \$3.00         | \$15.00         |
| xAI: Grok 3 Mini                                           | blackboxai/x-ai/grok-3-mini                                     | 131072             | \$0.30         | \$0.50          |
| xAI: Grok 3 Mini Beta                                      | blackboxai/x-ai/grok-3-mini-beta                                | 131072             | \$0.30         | \$0.50          |
| xAI: Grok Vision Beta                                      | blackboxai/x-ai/grok-vision-beta                                | 8192               | \$5.00         | \$15.00         |


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.blackbox.ai/llms.txt






# Web Search

> Enable real-time web search capabilities in your AI applications

## Overview

The BLACKBOX AI API provides powerful web search capabilities through the `blackbox-search` model. This feature allows your AI applications to access real-time information from the web, providing up-to-date answers with cited sources.

## Key Features

* **Real-time Information**: Access current data from the web
* **Source Citations**: Get URLs and titles of sources used
* **Seamless Integration**: Works with the standard chat completions API
* **Automatic Context**: Web results are automatically incorporated into responses

## Using Web Search

To enable web search, simply use the `blackbox-search` model in your chat completion requests:

<CodeGroup>
  ```bash cURL theme={null}
  curl --location 'https://api.blackbox.ai/v1/chat/completions' \
  --header 'Authorization: Bearer YOUR_API_KEY' \
  --header 'Content-Type: application/json' \
  --data '{
    "model": "blackboxai/blackbox-search",
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant that provides accurate, up-to-date information."
      },
      {
        "role": "user",
        "content": "What are the latest developments in AI from OpenAI?"
      }
    ],
  }'
  ```

  ```python Python theme={null}
  from openai import OpenAI
  import os

  client = OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/blackbox-search",
      messages=[
          {
              "role": "system",
              "content": "You are a helpful assistant that provides accurate, up-to-date information."
          },
          {
              "role": "user",
              "content": "What are the latest developments in AI from OpenAI?"
          }
      ],
      stream=False
  )

  print(response.choices[0].message.content)

  # Access citations if available
  if hasattr(response.choices[0].message, 'annotations'):
      for annotation in response.choices[0].message.annotations:
          if annotation.type == 'url_citation':
              print(f"\nSource: {annotation.url_citation.title}")
              print(f"URL: {annotation.url_citation.url}")
  ```

  ```javascript Node.js theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function searchWeb() {
    const response = await client.chat.completions.create({
      model: 'blackboxai/blackbox-search',
      messages: [
        {
          role: 'system',
          content: 'You are a helpful assistant that provides accurate, up-to-date information.'
        },
        {
          role: 'user',
          content: 'What are the latest developments in AI from OpenAI?'
        }
      ],
      stream: false
    });

    console.log(response.choices[0].message.content);

    // Access citations if available
    if (response.choices[0].message.annotations) {
      response.choices[0].message.annotations.forEach(annotation => {
        if (annotation.type === 'url_citation') {
          console.log(`\nSource: ${annotation.url_citation.title}`);
          console.log(`URL: ${annotation.url_citation.url}`);
        }
      });
    }
  }

  searchWeb();
  ```
</CodeGroup>

## Response Format

When using web search, the response includes an `annotations` array containing URL citations:

```json  theme={null}
{
  "id": "gen-...",
  "created": 1757140020,
  "model": "blackboxai/blackbox-search",
  "object": "chat.completion",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Here's the latest news I found: OpenAI recently announced...",
        "annotations": [
          {
            "type": "url_citation",
            "url_citation": {
              "url": "https://www.example.com/openai-news",
              "title": "Latest OpenAI Developments",
              "content": "Content of the web search result",
              "start_index": 100,
              "end_index": 200
            }
          }
        ]
      }
    }
  ],
  "usage": {
    "completion_tokens": 150,
    "prompt_tokens": 25,
    "total_tokens": 175
  }
}
```

## Annotations Structure

<ResponseField name="annotations" type="array">
  Array of annotation objects containing source citations.

  <Expandable title="Annotation Object">
    <ResponseField name="type" type="string">
      Type of annotation. Currently supports `url_citation`.
    </ResponseField>

    <ResponseField name="url_citation" type="object">
      Citation information for web sources.

      <Expandable title="URL Citation Object">
        <ResponseField name="url" type="string">
          The URL of the cited source.
        </ResponseField>

        <ResponseField name="title" type="string">
          The title of the web page or article.
        </ResponseField>

        <ResponseField name="content" type="string">
          Excerpt or summary of the content from the source (if available).
        </ResponseField>

        <ResponseField name="start_index" type="integer">
          The character index where the citation begins in the message content.
        </ResponseField>

        <ResponseField name="end_index" type="integer">
          The character index where the citation ends in the message content.
        </ResponseField>
      </Expandable>
    </ResponseField>
  </Expandable>
</ResponseField>

## Use Cases

### News and Current Events

```python  theme={null}
response = client.chat.completions.create(
    model="blackboxai/blackbox-search",
    messages=[
        {"role": "user", "content": "What are today's top technology news?"}
    ]
)
```

### Research and Fact-Checking

```python  theme={null}
response = client.chat.completions.create(
    model="blackboxai/blackbox-search",
    messages=[
        {"role": "user", "content": "What is the current population of Tokyo?"}
    ]
)
```

### Product Information

```python  theme={null}
response = client.chat.completions.create(
    model="blackboxai/blackbox-search",
    messages=[
        {"role": "user", "content": "Compare the latest iPhone and Samsung Galaxy models"}
    ]
)
```

### Market Data

```python  theme={null}
response = client.chat.completions.create(
    model="blackboxai/blackbox-search",
    messages=[
        {"role": "user", "content": "What is the current price of Bitcoin?"}
    ]
)
```

## Best Practices

1. **Be Specific**: Provide clear, specific queries for better search results
2. **Use System Messages**: Set context about the type of information needed
3. **Handle Citations**: Always check for and display source citations to users
4. **Rate Limiting**: Be mindful of API rate limits when making frequent searches
5. **Verify Information**: While web search provides current data, always encourage users to verify critical information

## Streaming with Web Search

Web search works seamlessly with streaming responses:

```python  theme={null}
stream = client.chat.completions.create(
    model="blackboxai/blackbox-search",
    messages=[
        {"role": "user", "content": "Latest AI breakthroughs in 2025"}
    ],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="", flush=True)
```

## Pricing

The `blackbox-search` model includes web search capabilities at the following rates:

* **Input**: \$0.0002 per 1K tokens
* **Output**: \$0.0005 per 1K tokens
* **Web Search**: \$0.03 for 1 search query (includes X/Twitter search)

See the [Chat Models](/api-reference/models/chat-models) page for complete pricing information.

## Related Resources

<CardGroup cols={2}>
  <Card title="Chat Completions" icon="message" href="/api-reference/chat">
    Learn about the chat completions API
  </Card>

  <Card title="Chat Models" icon="brain" href="/api-reference/models/chat-models">
    Explore all available chat models
  </Card>

  <Card title="Sample Usage" icon="code" href="/api-reference/sample-usage">
    See more API usage examples
  </Card>

  <Card title="CLI Web Search" icon="terminal" href="/features/blackbox-cli/key-features#web-search--real-time-information">
    Use web search in BLACKBOX CLI
  </Card>
</CardGroup>


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.blackbox.ai/llms.txt


# Sample Usage

> Examples of using BLACKBOX AI API for chat, image, and video models

Use BLACKBOX AI's rich API for Chat, Image, and Video models to directly integrate the power of AI into your applications.

# OpenAI Compatibility

BLACKBOX AI's API endpoints for chat, images, and video are fully compatible with OpenAI's API.

If you have an application that uses OpenAI's client libraries, you can configure it to point to BLACKBOX AI's API servers and use our models.

## Configuring OpenAI to use BLACKBOX AI's API

Pass your BLACKBOX AI API key to the `api_key` option and set the `base_url` to `https://api.blackbox.ai`:

<CodeGroup>
  ```python Python theme={null}
  import os
  import openai

  client = openai.OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from "openai";

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: "https://api.blackbox.ai",
  });
  ```
</CodeGroup>

You can find your API key in your BLACKBOX AI account settings.

## Querying a Chat Model

Query one of our [chat models](https://docs.blackbox.ai/api-reference/models/chat-models), like GPT-4:

<CodeGroup>
  ```python Python theme={null}
  import os
  import openai

  client = openai.OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/openai/gpt-4",
      messages=[
          {
              "role": "system",
              "content": "You are a helpful assistant.",
          },
          {
              "role": "user",
              "content": "What is the capital of France?",
          },
      ],
  )

  print(response.choices[0].message.content)
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  const response = await client.chat.completions.create({
    model: 'blackboxai/openai/gpt-4',
    messages: [
      { role: 'user', content: 'What is the capital of France?' },
    ],
  });

  console.log(response.choices[0].message.content);
  ```
</CodeGroup>

Output:

```text  theme={null}
The capital of France is Paris.
```

## Streaming a Chat Response

Use streaming to receive responses incrementally:

<CodeGroup>
  ```python Python theme={null}
  import os
  import openai

  client = openai.OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  stream = client.chat.completions.create(
      model="blackboxai/openai/gpt-4",
      messages=[
          {
              "role": "system",
              "content": "You are a helpful assistant.",
          },
          {"role": "user", "content": "Explain quantum computing briefly"},
      ],
      stream=True,
  )

  for chunk in stream:
      print(chunk.choices[0].delta.content or "", end="", flush=True)
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function run() {
    const stream = await client.chat.completions.create({
      model: 'blackboxai/openai/gpt-4',
      messages: [
        { role: 'system', content: 'You are a helpful assistant' },
        { role: 'user', content: 'Explain quantum computing briefly' },
      ],
      stream: true,
    });

    for await (const chunk of stream) {
      process.stdout.write(chunk.choices[0]?.delta?.content || '');
    }
  }

  run();
  ```
</CodeGroup>

## Image Generation

Generate images from text prompts using our image models:

<CodeGroup>
  ```python Python theme={null}
  from openai import OpenAI
  import os

  client = OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/black-forest-labs/flux-pro",
      messages=[
          {
              "role": "user",
              "content": "A futuristic cityscape at sunset",
          }
      ],
  )

  print(response.choices[0].message.content)  # URL to the generated image
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function main() {
    const response = await client.chat.completions.create({
      model: "blackboxai/black-forest-labs/flux-pro",
      messages: [
        { role: "user", content: "A futuristic cityscape at sunset" },
      ],
    });

    console.log(response.choices[0].message.content);  // URL to the generated image
  }

  main();
  ```
</CodeGroup>

The response content will be a URL to the generated image.

<div style={{textAlign: 'center'}}>
  <img src="https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=eec7f85d14dd143173d7fa98d8c49e08" alt="Generated Image" style={{width: '300px'}} data-og-width="1024" width="1024" data-og-height="1024" height="1024" data-path="images/image_gen.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=280&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=b3836f6f74269d7b42def7f138702467 280w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=560&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=15dca358a732dd67077254557e2e3e66 560w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=840&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=694427fcf187c02936c2c6a6bec833e0 840w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=1100&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=535eb0a74f1d4b07ac75d798147d54cd 1100w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=1650&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=801067a242a2ff037dc163941bb40340 1650w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=2500&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=cc87b2f16bf6f916325b63656266803a 2500w" />
</div>

## Video Generation

Generate videos from text prompts using our video models:

<CodeGroup>
  ```python Python theme={null}
  from openai import OpenAI
  import os

  client = OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/google/veo-2",
      messages=[
          {
              "role": "user",
              "content": "A Tesla car driving on a highway at dusk",
          }
      ],
  )

  print(response.choices[0].message.content)  # URL to the generated video
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function main() {
    const response = await client.chat.completions.create({
      model: "blackboxai/google/veo-2",
      messages: [
        { role: "user", content: "A Tesla car driving on a highway at dusk" },
      ],
    });

    console.log(response.choices[0].message.content);  // URL to the generated video
  }

  main();
  ```
</CodeGroup>

The response content will be a URL to the generated video.

<div style={{textAlign: 'center'}}>
  <video src="https://mintcdn.com/blackboxai-3b9e98f8/mNRwZ3veNst18-fs/videos/video_gen.mp4?fit=max&auto=format&n=mNRwZ3veNst18-fs&q=85&s=04faea3a9ba30a42e15f60f358f05967" width="560" height="315" controls data-path="videos/video_gen.mp4" />
</div>

## Web Search

Access real-time information from the web using the `blackbox-search` model:

<CodeGroup>
  ```python Python theme={null}
  from openai import OpenAI
  import os

  client = OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/blackbox-search",
      messages=[
          {
              "role": "system",
              "content": "You are a helpful assistant that provides accurate, up-to-date information.",
          },
          {
              "role": "user",
              "content": "What are the latest developments from OpenAI?",
          }
      ],
  )

  print(response.choices[0].message.content)

  # Access source citations
  if hasattr(response.choices[0].message, 'annotations'):
      print("\n--- Sources ---")
      for annotation in response.choices[0].message.annotations:
          if annotation.type == 'url_citation':
              print(f"Title: {annotation.url_citation.title}")
              print(f"URL: {annotation.url_citation.url}\n")
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function main() {
    const response = await client.chat.completions.create({
      model: "blackboxai/blackbox-search",
      messages: [
        {
          role: "system",
          content: "You are a helpful assistant that provides accurate, up-to-date information.",
        },
        {
          role: "user",
          content: "What are the latest developments from OpenAI?",
        },
      ],
    });

    console.log(response.choices[0].message.content);

    // Access source citations
    if (response.choices[0].message.annotations) {
      console.log("\n--- Sources ---");
      response.choices[0].message.annotations.forEach(annotation => {
        if (annotation.type === 'url_citation') {
          console.log(`Title: ${annotation.url_citation.title}`);
          console.log(`URL: ${annotation.url_citation.url}\n`);
        }
      });
    }
  }

  main();
  ```
</CodeGroup>

The `blackbox-search` model automatically searches the web and provides responses with source citations in the `annotations` field. Learn more about [Web Search](/api-reference/web-search).

<Accordion title="View Example Output">
  ```
  ### Recent Model Releases and Updates
  OpenAI has been advancing its GPT series rapidly. In mid-November 2025, they released **GPT-5.1**, described as a smarter, more conversational version of ChatGPT with improved reasoning capabilities. CEO Sam Altman has claimed that GPT-5 represents "PhD-level general intelligence," enabling complex problem-solving across domains. [[1]](https://theconversation.com/topics/openai-24920) This model supports up to 1 million token context limits in Azure OpenAI variants like GPT-4.1. [[2]](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/whats-new?view=foundry-classic)

  On December 3, 2025, OpenAI announced a proof-of-concept for **GPT-5 Thinking with 'confessions'**, a technique where the model generates a secondary "confession" output admitting to any shortcuts, rule-breaking, or non-compliance in its reasoning process. This aims to increase transparency, reducing "false negatives" (hidden misbehaviors) to just 4.4% in tests. They plan to scale this with other alignment methods like chain-of-thought monitoring. [[3]](https://x.com/i/status/1996281172377436557)

  Additionally, specialized models include **GPT-5.1-Codex-Max** for agentic coding tasks, handling long-running software development, and **Aardvark**, an agentic security researcher tool. [[4]](https://www.newsbytesapp.com/news/business/openai) Azure OpenAI also launched **GPT-4.1 and GPT-4.1-nano** with enhanced function calling, async support, and conversation mode for natural interactions. [[2]](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/whats-new?view=foundry-classic)

  ### Product Features and User Experience Enhancements
  ChatGPT continues to evolve with consumer-focused updates:
  - **Group chats**: Introduced in November 2025, allowing multiple users to collaborate in real-time. [[5]](https://openai.com/news/product-releases/)
  - **Integrated Voice Mode**: Rolled out on November 25, 2025, for mobile and web, enabling voice interactions within chats with real-time visuals, no separate mode required. Users can toggle back to the original setup. [[6]](https://x.com/i/status/1993381101369458763)
  - **Shopping Research**: Launched on November 24, 2025, this feature acts as an interactive buyer's guide, researching products across the web (prices, reviews, images) and personalizing based on user feedback and chat history. Usage is nearly unlimited through the holidays to aid gift shopping. [[7]](https://x.com/i/status/1993018357432586391)
  - **ChatGPT Atlas**: A new AI-powered web browser for seamless browsing within conversations. [[4]](https://www.newsbytesapp.com/news/business/openai)

  OpenAI paused app suggestions resembling ads in early December 2025 after user complaints, with Chief Research Officer Mark Chen acknowledging the misstep. Advertising initiatives, including those led by new Applications CEO Fidji Simo, have been deprioritized. [[8]](https://techcrunch.com/2025/12/07/openai-says-its-turned-off-app-suggestions-that-look-like-ads/)

  For Indian users, OpenAI made its mid-tier **ChatGPT Go** plan free for one year starting November 4, 2025, including access to GPT-5, faster responses, and higher limitstargeting its second-largest market. [[9]](https://economictimes.indiatimes.com/topic/openai)

  ### Enterprise and Adoption Growth
  Enterprise usage has surged: ChatGPT message volume grew 8x since November 2024, with custom GPTs (for workflows and institutional knowledge) jumping 19x to 20% of messages. API "reasoning tokens" increased 320x, indicating deeper AI integrationsaving workers up to an hour daily. Examples include BBVA using 4,000+ custom GPTs. [[10]](https://techcrunch.com/2025/12/08/openai-boasts-enterprise-win-days-after-internal-code-red-on-google-threat/)

  New third-party apps integrated into ChatGPT include @onepeloton, @Tripadvisor, and @Target for enhanced services. [[11]](https://x.com/i/status/1993125078436135008)

  ### Acquisitions and Infrastructure
  OpenAI acquired **Neptune** (AI model tracking tools) and **Software Applications, Inc.** (AI interface for Apple devices) to bolster development. [[12]](https://www.reuters.com/technology/openai/)[[4]](https://www.newsbytesapp.com/news/business/openai) They also inked a deal with NEXTDC for an AI campus and GPU supercluster in Sydney. [[12]](https://www.reuters.com/technology/openai/)

  Funding includes SoftBank's $22.5 billion second installment in a $41 billion round. [[4]](https://www.newsbytesapp.com/news/business/openai) The **Stargate Project** advances massive AI data centers, like the Abilene, Texas facility drawing from local water sources. [[1]](https://theconversation.com/topics/openai-24920) A compute leasing deal with Oracle provides 4.5 GW of data center power. [[13]](https://www.computerworld.com/article/4015023/openai-latest-news-and-insights.html)

  ### Legal and Ethical Developments
  - A U.S. judge ordered OpenAI to produce 20 million anonymized ChatGPT logs in a copyright lawsuit from The New York Times and others, though OpenAI is appealing, citing privacy. [[12]](https://www.reuters.com/technology/openai/)
  - In India, OpenAI told the Delhi High Court that deleting ChatGPT training data would violate U.S. law amid an ANI copyright suit. [[13]](https://www.computerworld.com/article/4015023/openai-latest-news-and-insights.html)
  - A German court ruled against OpenAI, awarding damages to GEMA for unauthorized use of song lyrics in training. [[9]](https://economictimes.indiatimes.com/topic/openai)

  Internally, Altman declared a "code red" in late November 2025, prioritizing ChatGPT improvements over other projects like ads due to competition from Google. [[8]](https://techcrunch.com/2025/12/07/openai-says-its-turned-off-app-suggestions-that-look-like-ads/)

  ### Philanthropy and Community
  The OpenAI Foundation announced the first **People-First AI Fund** recipients on December 3, 2025: 208 nonprofits receiving $40.5 million in unrestricted grants to ensure AI benefits underserved communities. [[14]](https://x.com/i/status/1996258322304155695)

  For more details, check OpenAI's official newsroom or podcast episodes discussing GPT-5.1 training. [[15]](https://x.com/i/status/1995923127982019030) These developments reflect OpenAI's push toward more capable, transparent, and accessible AI amid growing scrutiny.

  --- Sources ---
  Title: 1
  URL: https://theconversation.com/topics/openai-24920

  Title: 2
  URL: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/whats-new?view=foundry-classic

  Title: 3
  URL: https://x.com/i/status/1996281172377436557

  Title: 4
  URL: https://www.newsbytesapp.com/news/business/openai

  Title: 5
  URL: https://openai.com/news/product-releases/

  Title: 6
  URL: https://x.com/i/status/1993381101369458763

  Title: 7
  URL: https://x.com/i/status/1993018357432586391

  Title: 8
  URL: https://techcrunch.com/2025/12/07/openai-says-its-turned-off-app-suggestions-that-look-like-ads/

  Title: 9
  URL: https://economictimes.indiatimes.com/topic/openai

  Title: 10
  URL: https://techcrunch.com/2025/12/08/openai-boasts-enterprise-win-days-after-internal-code-red-on-google-threat/

  Title: 11
  URL: https://x.com/i/status/1993125078436135008

  Title: 12
  URL: https://www.reuters.com/technology/openai/

  Title: 13
  URL: https://www.computerworld.com/article/4015023/openai-latest-news-and-insights.html

  Title: 14
  URL: https://x.com/i/status/1996258322304155695

  Title: 15
  URL: https://x.com/i/status/1995923127982019030
  ```
</Accordion>


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.blackbox.ai/llms.txt


# Sample Usage

> Examples of using BLACKBOX AI API for chat, image, and video models

Use BLACKBOX AI's rich API for Chat, Image, and Video models to directly integrate the power of AI into your applications.

# OpenAI Compatibility

BLACKBOX AI's API endpoints for chat, images, and video are fully compatible with OpenAI's API.

If you have an application that uses OpenAI's client libraries, you can configure it to point to BLACKBOX AI's API servers and use our models.

## Configuring OpenAI to use BLACKBOX AI's API

Pass your BLACKBOX AI API key to the `api_key` option and set the `base_url` to `https://api.blackbox.ai`:

<CodeGroup>
  ```python Python theme={null}
  import os
  import openai

  client = openai.OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from "openai";

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: "https://api.blackbox.ai",
  });
  ```
</CodeGroup>

You can find your API key in your BLACKBOX AI account settings.

## Querying a Chat Model

Query one of our [chat models](https://docs.blackbox.ai/api-reference/models/chat-models), like GPT-4:

<CodeGroup>
  ```python Python theme={null}
  import os
  import openai

  client = openai.OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/openai/gpt-4",
      messages=[
          {
              "role": "system",
              "content": "You are a helpful assistant.",
          },
          {
              "role": "user",
              "content": "What is the capital of France?",
          },
      ],
  )

  print(response.choices[0].message.content)
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  const response = await client.chat.completions.create({
    model: 'blackboxai/openai/gpt-4',
    messages: [
      { role: 'user', content: 'What is the capital of France?' },
    ],
  });

  console.log(response.choices[0].message.content);
  ```
</CodeGroup>

Output:

```text  theme={null}
The capital of France is Paris.
```

## Streaming a Chat Response

Use streaming to receive responses incrementally:

<CodeGroup>
  ```python Python theme={null}
  import os
  import openai

  client = openai.OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  stream = client.chat.completions.create(
      model="blackboxai/openai/gpt-4",
      messages=[
          {
              "role": "system",
              "content": "You are a helpful assistant.",
          },
          {"role": "user", "content": "Explain quantum computing briefly"},
      ],
      stream=True,
  )

  for chunk in stream:
      print(chunk.choices[0].delta.content or "", end="", flush=True)
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function run() {
    const stream = await client.chat.completions.create({
      model: 'blackboxai/openai/gpt-4',
      messages: [
        { role: 'system', content: 'You are a helpful assistant' },
        { role: 'user', content: 'Explain quantum computing briefly' },
      ],
      stream: true,
    });

    for await (const chunk of stream) {
      process.stdout.write(chunk.choices[0]?.delta?.content || '');
    }
  }

  run();
  ```
</CodeGroup>

## Image Generation

Generate images from text prompts using our image models:

<CodeGroup>
  ```python Python theme={null}
  from openai import OpenAI
  import os

  client = OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/black-forest-labs/flux-pro",
      messages=[
          {
              "role": "user",
              "content": "A futuristic cityscape at sunset",
          }
      ],
  )

  print(response.choices[0].message.content)  # URL to the generated image
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function main() {
    const response = await client.chat.completions.create({
      model: "blackboxai/black-forest-labs/flux-pro",
      messages: [
        { role: "user", content: "A futuristic cityscape at sunset" },
      ],
    });

    console.log(response.choices[0].message.content);  // URL to the generated image
  }

  main();
  ```
</CodeGroup>

The response content will be a URL to the generated image.

<div style={{textAlign: 'center'}}>
  <img src="https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=eec7f85d14dd143173d7fa98d8c49e08" alt="Generated Image" style={{width: '300px'}} data-og-width="1024" width="1024" data-og-height="1024" height="1024" data-path="images/image_gen.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=280&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=b3836f6f74269d7b42def7f138702467 280w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=560&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=15dca358a732dd67077254557e2e3e66 560w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=840&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=694427fcf187c02936c2c6a6bec833e0 840w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=1100&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=535eb0a74f1d4b07ac75d798147d54cd 1100w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=1650&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=801067a242a2ff037dc163941bb40340 1650w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=2500&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=cc87b2f16bf6f916325b63656266803a 2500w" />
</div>

## Video Generation

Generate videos from text prompts using our video models:

<CodeGroup>
  ```python Python theme={null}
  from openai import OpenAI
  import os

  client = OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/google/veo-2",
      messages=[
          {
              "role": "user",
              "content": "A Tesla car driving on a highway at dusk",
          }
      ],
  )

  print(response.choices[0].message.content)  # URL to the generated video
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function main() {
    const response = await client.chat.completions.create({
      model: "blackboxai/google/veo-2",
      messages: [
        { role: "user", content: "A Tesla car driving on a highway at dusk" },
      ],
    });

    console.log(response.choices[0].message.content);  // URL to the generated video
  }

  main();
  ```
</CodeGroup>

The response content will be a URL to the generated video.

<div style={{textAlign: 'center'}}>
  <video src="https://mintcdn.com/blackboxai-3b9e98f8/mNRwZ3veNst18-fs/videos/video_gen.mp4?fit=max&auto=format&n=mNRwZ3veNst18-fs&q=85&s=04faea3a9ba30a42e15f60f358f05967" width="560" height="315" controls data-path="videos/video_gen.mp4" />
</div>

## Web Search

Access real-time information from the web using the `blackbox-search` model:

<CodeGroup>
  ```python Python theme={null}
  from openai import OpenAI
  import os

  client = OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/blackbox-search",
      messages=[
          {
              "role": "system",
              "content": "You are a helpful assistant that provides accurate, up-to-date information.",
          },
          {
              "role": "user",
              "content": "What are the latest developments from OpenAI?",
          }
      ],
  )

  print(response.choices[0].message.content)

  # Access source citations
  if hasattr(response.choices[0].message, 'annotations'):
      print("\n--- Sources ---")
      for annotation in response.choices[0].message.annotations:
          if annotation.type == 'url_citation':
              print(f"Title: {annotation.url_citation.title}")
              print(f"URL: {annotation.url_citation.url}\n")
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function main() {
    const response = await client.chat.completions.create({
      model: "blackboxai/blackbox-search",
      messages: [
        {
          role: "system",
          content: "You are a helpful assistant that provides accurate, up-to-date information.",
        },
        {
          role: "user",
          content: "What are the latest developments from OpenAI?",
        },
      ],
    });

    console.log(response.choices[0].message.content);

    // Access source citations
    if (response.choices[0].message.annotations) {
      console.log("\n--- Sources ---");
      response.choices[0].message.annotations.forEach(annotation => {
        if (annotation.type === 'url_citation') {
          console.log(`Title: ${annotation.url_citation.title}`);
          console.log(`URL: ${annotation.url_citation.url}\n`);
        }
      });
    }
  }

  main();
  ```
</CodeGroup>

The `blackbox-search` model automatically searches the web and provides responses with source citations in the `annotations` field. Learn more about [Web Search](/api-reference/web-search).

<Accordion title="View Example Output">
  ```
  ### Recent Model Releases and Updates
  OpenAI has been advancing its GPT series rapidly. In mid-November 2025, they released **GPT-5.1**, described as a smarter, more conversational version of ChatGPT with improved reasoning capabilities. CEO Sam Altman has claimed that GPT-5 represents "PhD-level general intelligence," enabling complex problem-solving across domains. [[1]](https://theconversation.com/topics/openai-24920) This model supports up to 1 million token context limits in Azure OpenAI variants like GPT-4.1. [[2]](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/whats-new?view=foundry-classic)

  On December 3, 2025, OpenAI announced a proof-of-concept for **GPT-5 Thinking with 'confessions'**, a technique where the model generates a secondary "confession" output admitting to any shortcuts, rule-breaking, or non-compliance in its reasoning process. This aims to increase transparency, reducing "false negatives" (hidden misbehaviors) to just 4.4% in tests. They plan to scale this with other alignment methods like chain-of-thought monitoring. [[3]](https://x.com/i/status/1996281172377436557)

  Additionally, specialized models include **GPT-5.1-Codex-Max** for agentic coding tasks, handling long-running software development, and **Aardvark**, an agentic security researcher tool. [[4]](https://www.newsbytesapp.com/news/business/openai) Azure OpenAI also launched **GPT-4.1 and GPT-4.1-nano** with enhanced function calling, async support, and conversation mode for natural interactions. [[2]](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/whats-new?view=foundry-classic)

  ### Product Features and User Experience Enhancements
  ChatGPT continues to evolve with consumer-focused updates:
  - **Group chats**: Introduced in November 2025, allowing multiple users to collaborate in real-time. [[5]](https://openai.com/news/product-releases/)
  - **Integrated Voice Mode**: Rolled out on November 25, 2025, for mobile and web, enabling voice interactions within chats with real-time visuals, no separate mode required. Users can toggle back to the original setup. [[6]](https://x.com/i/status/1993381101369458763)
  - **Shopping Research**: Launched on November 24, 2025, this feature acts as an interactive buyer's guide, researching products across the web (prices, reviews, images) and personalizing based on user feedback and chat history. Usage is nearly unlimited through the holidays to aid gift shopping. [[7]](https://x.com/i/status/1993018357432586391)
  - **ChatGPT Atlas**: A new AI-powered web browser for seamless browsing within conversations. [[4]](https://www.newsbytesapp.com/news/business/openai)

  OpenAI paused app suggestions resembling ads in early December 2025 after user complaints, with Chief Research Officer Mark Chen acknowledging the misstep. Advertising initiatives, including those led by new Applications CEO Fidji Simo, have been deprioritized. [[8]](https://techcrunch.com/2025/12/07/openai-says-its-turned-off-app-suggestions-that-look-like-ads/)

  For Indian users, OpenAI made its mid-tier **ChatGPT Go** plan free for one year starting November 4, 2025, including access to GPT-5, faster responses, and higher limitstargeting its second-largest market. [[9]](https://economictimes.indiatimes.com/topic/openai)

  ### Enterprise and Adoption Growth
  Enterprise usage has surged: ChatGPT message volume grew 8x since November 2024, with custom GPTs (for workflows and institutional knowledge) jumping 19x to 20% of messages. API "reasoning tokens" increased 320x, indicating deeper AI integrationsaving workers up to an hour daily. Examples include BBVA using 4,000+ custom GPTs. [[10]](https://techcrunch.com/2025/12/08/openai-boasts-enterprise-win-days-after-internal-code-red-on-google-threat/)

  New third-party apps integrated into ChatGPT include @onepeloton, @Tripadvisor, and @Target for enhanced services. [[11]](https://x.com/i/status/1993125078436135008)

  ### Acquisitions and Infrastructure
  OpenAI acquired **Neptune** (AI model tracking tools) and **Software Applications, Inc.** (AI interface for Apple devices) to bolster development. [[12]](https://www.reuters.com/technology/openai/)[[4]](https://www.newsbytesapp.com/news/business/openai) They also inked a deal with NEXTDC for an AI campus and GPU supercluster in Sydney. [[12]](https://www.reuters.com/technology/openai/)

  Funding includes SoftBank's $22.5 billion second installment in a $41 billion round. [[4]](https://www.newsbytesapp.com/news/business/openai) The **Stargate Project** advances massive AI data centers, like the Abilene, Texas facility drawing from local water sources. [[1]](https://theconversation.com/topics/openai-24920) A compute leasing deal with Oracle provides 4.5 GW of data center power. [[13]](https://www.computerworld.com/article/4015023/openai-latest-news-and-insights.html)

  ### Legal and Ethical Developments
  - A U.S. judge ordered OpenAI to produce 20 million anonymized ChatGPT logs in a copyright lawsuit from The New York Times and others, though OpenAI is appealing, citing privacy. [[12]](https://www.reuters.com/technology/openai/)
  - In India, OpenAI told the Delhi High Court that deleting ChatGPT training data would violate U.S. law amid an ANI copyright suit. [[13]](https://www.computerworld.com/article/4015023/openai-latest-news-and-insights.html)
  - A German court ruled against OpenAI, awarding damages to GEMA for unauthorized use of song lyrics in training. [[9]](https://economictimes.indiatimes.com/topic/openai)

  Internally, Altman declared a "code red" in late November 2025, prioritizing ChatGPT improvements over other projects like ads due to competition from Google. [[8]](https://techcrunch.com/2025/12/07/openai-says-its-turned-off-app-suggestions-that-look-like-ads/)

  ### Philanthropy and Community
  The OpenAI Foundation announced the first **People-First AI Fund** recipients on December 3, 2025: 208 nonprofits receiving $40.5 million in unrestricted grants to ensure AI benefits underserved communities. [[14]](https://x.com/i/status/1996258322304155695)

  For more details, check OpenAI's official newsroom or podcast episodes discussing GPT-5.1 training. [[15]](https://x.com/i/status/1995923127982019030) These developments reflect OpenAI's push toward more capable, transparent, and accessible AI amid growing scrutiny.

  --- Sources ---
  Title: 1
  URL: https://theconversation.com/topics/openai-24920

  Title: 2
  URL: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/whats-new?view=foundry-classic

  Title: 3
  URL: https://x.com/i/status/1996281172377436557

  Title: 4
  URL: https://www.newsbytesapp.com/news/business/openai

  Title: 5
  URL: https://openai.com/news/product-releases/

  Title: 6
  URL: https://x.com/i/status/1993381101369458763

  Title: 7
  URL: https://x.com/i/status/1993018357432586391

  Title: 8
  URL: https://techcrunch.com/2025/12/07/openai-says-its-turned-off-app-suggestions-that-look-like-ads/

  Title: 9
  URL: https://economictimes.indiatimes.com/topic/openai

  Title: 10
  URL: https://techcrunch.com/2025/12/08/openai-boasts-enterprise-win-days-after-internal-code-red-on-google-threat/

  Title: 11
  URL: https://x.com/i/status/1993125078436135008

  Title: 12
  URL: https://www.reuters.com/technology/openai/

  Title: 13
  URL: https://www.computerworld.com/article/4015023/openai-latest-news-and-insights.html

  Title: 14
  URL: https://x.com/i/status/1996258322304155695

  Title: 15
  URL: https://x.com/i/status/1995923127982019030
  ```
</Accordion>


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.blackbox.ai/llms.txt

# Sample Usage

> Examples of using BLACKBOX AI API for chat, image, and video models

Use BLACKBOX AI's rich API for Chat, Image, and Video models to directly integrate the power of AI into your applications.

# OpenAI Compatibility

BLACKBOX AI's API endpoints for chat, images, and video are fully compatible with OpenAI's API.

If you have an application that uses OpenAI's client libraries, you can configure it to point to BLACKBOX AI's API servers and use our models.

## Configuring OpenAI to use BLACKBOX AI's API

Pass your BLACKBOX AI API key to the `api_key` option and set the `base_url` to `https://api.blackbox.ai`:

<CodeGroup>
  ```python Python theme={null}
  import os
  import openai

  client = openai.OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from "openai";

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: "https://api.blackbox.ai",
  });
  ```
</CodeGroup>

You can find your API key in your BLACKBOX AI account settings.

## Querying a Chat Model

Query one of our [chat models](https://docs.blackbox.ai/api-reference/models/chat-models), like GPT-4:

<CodeGroup>
  ```python Python theme={null}
  import os
  import openai

  client = openai.OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/openai/gpt-4",
      messages=[
          {
              "role": "system",
              "content": "You are a helpful assistant.",
          },
          {
              "role": "user",
              "content": "What is the capital of France?",
          },
      ],
  )

  print(response.choices[0].message.content)
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  const response = await client.chat.completions.create({
    model: 'blackboxai/openai/gpt-4',
    messages: [
      { role: 'user', content: 'What is the capital of France?' },
    ],
  });

  console.log(response.choices[0].message.content);
  ```
</CodeGroup>

Output:

```text  theme={null}
The capital of France is Paris.
```

## Streaming a Chat Response

Use streaming to receive responses incrementally:

<CodeGroup>
  ```python Python theme={null}
  import os
  import openai

  client = openai.OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  stream = client.chat.completions.create(
      model="blackboxai/openai/gpt-4",
      messages=[
          {
              "role": "system",
              "content": "You are a helpful assistant.",
          },
          {"role": "user", "content": "Explain quantum computing briefly"},
      ],
      stream=True,
  )

  for chunk in stream:
      print(chunk.choices[0].delta.content or "", end="", flush=True)
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function run() {
    const stream = await client.chat.completions.create({
      model: 'blackboxai/openai/gpt-4',
      messages: [
        { role: 'system', content: 'You are a helpful assistant' },
        { role: 'user', content: 'Explain quantum computing briefly' },
      ],
      stream: true,
    });

    for await (const chunk of stream) {
      process.stdout.write(chunk.choices[0]?.delta?.content || '');
    }
  }

  run();
  ```
</CodeGroup>

## Image Generation

Generate images from text prompts using our image models:

<CodeGroup>
  ```python Python theme={null}
  from openai import OpenAI
  import os

  client = OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/black-forest-labs/flux-pro",
      messages=[
          {
              "role": "user",
              "content": "A futuristic cityscape at sunset",
          }
      ],
  )

  print(response.choices[0].message.content)  # URL to the generated image
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function main() {
    const response = await client.chat.completions.create({
      model: "blackboxai/black-forest-labs/flux-pro",
      messages: [
        { role: "user", content: "A futuristic cityscape at sunset" },
      ],
    });

    console.log(response.choices[0].message.content);  // URL to the generated image
  }

  main();
  ```
</CodeGroup>

The response content will be a URL to the generated image.

<div style={{textAlign: 'center'}}>
  <img src="https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=eec7f85d14dd143173d7fa98d8c49e08" alt="Generated Image" style={{width: '300px'}} data-og-width="1024" width="1024" data-og-height="1024" height="1024" data-path="images/image_gen.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=280&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=b3836f6f74269d7b42def7f138702467 280w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=560&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=15dca358a732dd67077254557e2e3e66 560w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=840&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=694427fcf187c02936c2c6a6bec833e0 840w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=1100&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=535eb0a74f1d4b07ac75d798147d54cd 1100w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=1650&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=801067a242a2ff037dc163941bb40340 1650w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=2500&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=cc87b2f16bf6f916325b63656266803a 2500w" />
</div>

## Video Generation

Generate videos from text prompts using our video models:

<CodeGroup>
  ```python Python theme={null}
  from openai import OpenAI
  import os

  client = OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/google/veo-2",
      messages=[
          {
              "role": "user",
              "content": "A Tesla car driving on a highway at dusk",
          }
      ],
  )

  print(response.choices[0].message.content)  # URL to the generated video
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function main() {
    const response = await client.chat.completions.create({
      model: "blackboxai/google/veo-2",
      messages: [
        { role: "user", content: "A Tesla car driving on a highway at dusk" },
      ],
    });

    console.log(response.choices[0].message.content);  // URL to the generated video
  }

  main();
  ```
</CodeGroup>

The response content will be a URL to the generated video.

<div style={{textAlign: 'center'}}>
  <video src="https://mintcdn.com/blackboxai-3b9e98f8/mNRwZ3veNst18-fs/videos/video_gen.mp4?fit=max&auto=format&n=mNRwZ3veNst18-fs&q=85&s=04faea3a9ba30a42e15f60f358f05967" width="560" height="315" controls data-path="videos/video_gen.mp4" />
</div>

## Web Search

Access real-time information from the web using the `blackbox-search` model:

<CodeGroup>
  ```python Python theme={null}
  from openai import OpenAI
  import os

  client = OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/blackbox-search",
      messages=[
          {
              "role": "system",
              "content": "You are a helpful assistant that provides accurate, up-to-date information.",
          },
          {
              "role": "user",
              "content": "What are the latest developments from OpenAI?",
          }
      ],
  )

  print(response.choices[0].message.content)

  # Access source citations
  if hasattr(response.choices[0].message, 'annotations'):
      print("\n--- Sources ---")
      for annotation in response.choices[0].message.annotations:
          if annotation.type == 'url_citation':
              print(f"Title: {annotation.url_citation.title}")
              print(f"URL: {annotation.url_citation.url}\n")
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function main() {
    const response = await client.chat.completions.create({
      model: "blackboxai/blackbox-search",
      messages: [
        {
          role: "system",
          content: "You are a helpful assistant that provides accurate, up-to-date information.",
        },
        {
          role: "user",
          content: "What are the latest developments from OpenAI?",
        },
      ],
    });

    console.log(response.choices[0].message.content);

    // Access source citations
    if (response.choices[0].message.annotations) {
      console.log("\n--- Sources ---");
      response.choices[0].message.annotations.forEach(annotation => {
        if (annotation.type === 'url_citation') {
          console.log(`Title: ${annotation.url_citation.title}`);
          console.log(`URL: ${annotation.url_citation.url}\n`);
        }
      });
    }
  }

  main();
  ```
</CodeGroup>

The `blackbox-search` model automatically searches the web and provides responses with source citations in the `annotations` field. Learn more about [Web Search](/api-reference/web-search).

<Accordion title="View Example Output">
  ```
  ### Recent Model Releases and Updates
  OpenAI has been advancing its GPT series rapidly. In mid-November 2025, they released **GPT-5.1**, described as a smarter, more conversational version of ChatGPT with improved reasoning capabilities. CEO Sam Altman has claimed that GPT-5 represents "PhD-level general intelligence," enabling complex problem-solving across domains. [[1]](https://theconversation.com/topics/openai-24920) This model supports up to 1 million token context limits in Azure OpenAI variants like GPT-4.1. [[2]](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/whats-new?view=foundry-classic)

  On December 3, 2025, OpenAI announced a proof-of-concept for **GPT-5 Thinking with 'confessions'**, a technique where the model generates a secondary "confession" output admitting to any shortcuts, rule-breaking, or non-compliance in its reasoning process. This aims to increase transparency, reducing "false negatives" (hidden misbehaviors) to just 4.4% in tests. They plan to scale this with other alignment methods like chain-of-thought monitoring. [[3]](https://x.com/i/status/1996281172377436557)

  Additionally, specialized models include **GPT-5.1-Codex-Max** for agentic coding tasks, handling long-running software development, and **Aardvark**, an agentic security researcher tool. [[4]](https://www.newsbytesapp.com/news/business/openai) Azure OpenAI also launched **GPT-4.1 and GPT-4.1-nano** with enhanced function calling, async support, and conversation mode for natural interactions. [[2]](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/whats-new?view=foundry-classic)

  ### Product Features and User Experience Enhancements
  ChatGPT continues to evolve with consumer-focused updates:
  - **Group chats**: Introduced in November 2025, allowing multiple users to collaborate in real-time. [[5]](https://openai.com/news/product-releases/)
  - **Integrated Voice Mode**: Rolled out on November 25, 2025, for mobile and web, enabling voice interactions within chats with real-time visuals, no separate mode required. Users can toggle back to the original setup. [[6]](https://x.com/i/status/1993381101369458763)
  - **Shopping Research**: Launched on November 24, 2025, this feature acts as an interactive buyer's guide, researching products across the web (prices, reviews, images) and personalizing based on user feedback and chat history. Usage is nearly unlimited through the holidays to aid gift shopping. [[7]](https://x.com/i/status/1993018357432586391)
  - **ChatGPT Atlas**: A new AI-powered web browser for seamless browsing within conversations. [[4]](https://www.newsbytesapp.com/news/business/openai)

  OpenAI paused app suggestions resembling ads in early December 2025 after user complaints, with Chief Research Officer Mark Chen acknowledging the misstep. Advertising initiatives, including those led by new Applications CEO Fidji Simo, have been deprioritized. [[8]](https://techcrunch.com/2025/12/07/openai-says-its-turned-off-app-suggestions-that-look-like-ads/)

  For Indian users, OpenAI made its mid-tier **ChatGPT Go** plan free for one year starting November 4, 2025, including access to GPT-5, faster responses, and higher limitstargeting its second-largest market. [[9]](https://economictimes.indiatimes.com/topic/openai)

  ### Enterprise and Adoption Growth
  Enterprise usage has surged: ChatGPT message volume grew 8x since November 2024, with custom GPTs (for workflows and institutional knowledge) jumping 19x to 20% of messages. API "reasoning tokens" increased 320x, indicating deeper AI integrationsaving workers up to an hour daily. Examples include BBVA using 4,000+ custom GPTs. [[10]](https://techcrunch.com/2025/12/08/openai-boasts-enterprise-win-days-after-internal-code-red-on-google-threat/)

  New third-party apps integrated into ChatGPT include @onepeloton, @Tripadvisor, and @Target for enhanced services. [[11]](https://x.com/i/status/1993125078436135008)

  ### Acquisitions and Infrastructure
  OpenAI acquired **Neptune** (AI model tracking tools) and **Software Applications, Inc.** (AI interface for Apple devices) to bolster development. [[12]](https://www.reuters.com/technology/openai/)[[4]](https://www.newsbytesapp.com/news/business/openai) They also inked a deal with NEXTDC for an AI campus and GPU supercluster in Sydney. [[12]](https://www.reuters.com/technology/openai/)

  Funding includes SoftBank's $22.5 billion second installment in a $41 billion round. [[4]](https://www.newsbytesapp.com/news/business/openai) The **Stargate Project** advances massive AI data centers, like the Abilene, Texas facility drawing from local water sources. [[1]](https://theconversation.com/topics/openai-24920) A compute leasing deal with Oracle provides 4.5 GW of data center power. [[13]](https://www.computerworld.com/article/4015023/openai-latest-news-and-insights.html)

  ### Legal and Ethical Developments
  - A U.S. judge ordered OpenAI to produce 20 million anonymized ChatGPT logs in a copyright lawsuit from The New York Times and others, though OpenAI is appealing, citing privacy. [[12]](https://www.reuters.com/technology/openai/)
  - In India, OpenAI told the Delhi High Court that deleting ChatGPT training data would violate U.S. law amid an ANI copyright suit. [[13]](https://www.computerworld.com/article/4015023/openai-latest-news-and-insights.html)
  - A German court ruled against OpenAI, awarding damages to GEMA for unauthorized use of song lyrics in training. [[9]](https://economictimes.indiatimes.com/topic/openai)

  Internally, Altman declared a "code red" in late November 2025, prioritizing ChatGPT improvements over other projects like ads due to competition from Google. [[8]](https://techcrunch.com/2025/12/07/openai-says-its-turned-off-app-suggestions-that-look-like-ads/)

  ### Philanthropy and Community
  The OpenAI Foundation announced the first **People-First AI Fund** recipients on December 3, 2025: 208 nonprofits receiving $40.5 million in unrestricted grants to ensure AI benefits underserved communities. [[14]](https://x.com/i/status/1996258322304155695)

  For more details, check OpenAI's official newsroom or podcast episodes discussing GPT-5.1 training. [[15]](https://x.com/i/status/1995923127982019030) These developments reflect OpenAI's push toward more capable, transparent, and accessible AI amid growing scrutiny.

  --- Sources ---
  Title: 1
  URL: https://theconversation.com/topics/openai-24920

  Title: 2
  URL: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/whats-new?view=foundry-classic

  Title: 3
  URL: https://x.com/i/status/1996281172377436557

  Title: 4
  URL: https://www.newsbytesapp.com/news/business/openai

  Title: 5
  URL: https://openai.com/news/product-releases/

  Title: 6
  URL: https://x.com/i/status/1993381101369458763

  Title: 7
  URL: https://x.com/i/status/1993018357432586391

  Title: 8
  URL: https://techcrunch.com/2025/12/07/openai-says-its-turned-off-app-suggestions-that-look-like-ads/

  Title: 9
  URL: https://economictimes.indiatimes.com/topic/openai

  Title: 10
  URL: https://techcrunch.com/2025/12/08/openai-boasts-enterprise-win-days-after-internal-code-red-on-google-threat/

  Title: 11
  URL: https://x.com/i/status/1993125078436135008

  Title: 12
  URL: https://www.reuters.com/technology/openai/

  Title: 13
  URL: https://www.computerworld.com/article/4015023/openai-latest-news-and-insights.html

  Title: 14
  URL: https://x.com/i/status/1996258322304155695

  Title: 15
  URL: https://x.com/i/status/1995923127982019030
  ```
</Accordion>


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.blackbox.ai/llms.txt


# Sample Usage

> Examples of using BLACKBOX AI API for chat, image, and video models

Use BLACKBOX AI's rich API for Chat, Image, and Video models to directly integrate the power of AI into your applications.

# OpenAI Compatibility

BLACKBOX AI's API endpoints for chat, images, and video are fully compatible with OpenAI's API.

If you have an application that uses OpenAI's client libraries, you can configure it to point to BLACKBOX AI's API servers and use our models.

## Configuring OpenAI to use BLACKBOX AI's API

Pass your BLACKBOX AI API key to the `api_key` option and set the `base_url` to `https://api.blackbox.ai`:

<CodeGroup>
  ```python Python theme={null}
  import os
  import openai

  client = openai.OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from "openai";

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: "https://api.blackbox.ai",
  });
  ```
</CodeGroup>

You can find your API key in your BLACKBOX AI account settings.

## Querying a Chat Model

Query one of our [chat models](https://docs.blackbox.ai/api-reference/models/chat-models), like GPT-4:

<CodeGroup>
  ```python Python theme={null}
  import os
  import openai

  client = openai.OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/openai/gpt-4",
      messages=[
          {
              "role": "system",
              "content": "You are a helpful assistant.",
          },
          {
              "role": "user",
              "content": "What is the capital of France?",
          },
      ],
  )

  print(response.choices[0].message.content)
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  const response = await client.chat.completions.create({
    model: 'blackboxai/openai/gpt-4',
    messages: [
      { role: 'user', content: 'What is the capital of France?' },
    ],
  });

  console.log(response.choices[0].message.content);
  ```
</CodeGroup>

Output:

```text  theme={null}
The capital of France is Paris.
```

## Streaming a Chat Response

Use streaming to receive responses incrementally:

<CodeGroup>
  ```python Python theme={null}
  import os
  import openai

  client = openai.OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  stream = client.chat.completions.create(
      model="blackboxai/openai/gpt-4",
      messages=[
          {
              "role": "system",
              "content": "You are a helpful assistant.",
          },
          {"role": "user", "content": "Explain quantum computing briefly"},
      ],
      stream=True,
  )

  for chunk in stream:
      print(chunk.choices[0].delta.content or "", end="", flush=True)
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function run() {
    const stream = await client.chat.completions.create({
      model: 'blackboxai/openai/gpt-4',
      messages: [
        { role: 'system', content: 'You are a helpful assistant' },
        { role: 'user', content: 'Explain quantum computing briefly' },
      ],
      stream: true,
    });

    for await (const chunk of stream) {
      process.stdout.write(chunk.choices[0]?.delta?.content || '');
    }
  }

  run();
  ```
</CodeGroup>

## Image Generation

Generate images from text prompts using our image models:

<CodeGroup>
  ```python Python theme={null}
  from openai import OpenAI
  import os

  client = OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/black-forest-labs/flux-pro",
      messages=[
          {
              "role": "user",
              "content": "A futuristic cityscape at sunset",
          }
      ],
  )

  print(response.choices[0].message.content)  # URL to the generated image
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function main() {
    const response = await client.chat.completions.create({
      model: "blackboxai/black-forest-labs/flux-pro",
      messages: [
        { role: "user", content: "A futuristic cityscape at sunset" },
      ],
    });

    console.log(response.choices[0].message.content);  // URL to the generated image
  }

  main();
  ```
</CodeGroup>

The response content will be a URL to the generated image.

<div style={{textAlign: 'center'}}>
  <img src="https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=eec7f85d14dd143173d7fa98d8c49e08" alt="Generated Image" style={{width: '300px'}} data-og-width="1024" width="1024" data-og-height="1024" height="1024" data-path="images/image_gen.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=280&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=b3836f6f74269d7b42def7f138702467 280w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=560&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=15dca358a732dd67077254557e2e3e66 560w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=840&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=694427fcf187c02936c2c6a6bec833e0 840w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=1100&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=535eb0a74f1d4b07ac75d798147d54cd 1100w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=1650&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=801067a242a2ff037dc163941bb40340 1650w, https://mintcdn.com/blackboxai-3b9e98f8/rUuDb8VjH2C7FoZQ/images/image_gen.png?w=2500&fit=max&auto=format&n=rUuDb8VjH2C7FoZQ&q=85&s=cc87b2f16bf6f916325b63656266803a 2500w" />
</div>

## Video Generation

Generate videos from text prompts using our video models:

<CodeGroup>
  ```python Python theme={null}
  from openai import OpenAI
  import os

  client = OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/google/veo-2",
      messages=[
          {
              "role": "user",
              "content": "A Tesla car driving on a highway at dusk",
          }
      ],
  )

  print(response.choices[0].message.content)  # URL to the generated video
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function main() {
    const response = await client.chat.completions.create({
      model: "blackboxai/google/veo-2",
      messages: [
        { role: "user", content: "A Tesla car driving on a highway at dusk" },
      ],
    });

    console.log(response.choices[0].message.content);  // URL to the generated video
  }

  main();
  ```
</CodeGroup>

The response content will be a URL to the generated video.

<div style={{textAlign: 'center'}}>
  <video src="https://mintcdn.com/blackboxai-3b9e98f8/mNRwZ3veNst18-fs/videos/video_gen.mp4?fit=max&auto=format&n=mNRwZ3veNst18-fs&q=85&s=04faea3a9ba30a42e15f60f358f05967" width="560" height="315" controls data-path="videos/video_gen.mp4" />
</div>

## Web Search

Access real-time information from the web using the `blackbox-search` model:

<CodeGroup>
  ```python Python theme={null}
  from openai import OpenAI
  import os

  client = OpenAI(
      api_key=os.environ.get("BLACKBOX_API_KEY"),
      base_url="https://api.blackbox.ai",
  )

  response = client.chat.completions.create(
      model="blackboxai/blackbox-search",
      messages=[
          {
              "role": "system",
              "content": "You are a helpful assistant that provides accurate, up-to-date information.",
          },
          {
              "role": "user",
              "content": "What are the latest developments from OpenAI?",
          }
      ],
  )

  print(response.choices[0].message.content)

  # Access source citations
  if hasattr(response.choices[0].message, 'annotations'):
      print("\n--- Sources ---")
      for annotation in response.choices[0].message.annotations:
          if annotation.type == 'url_citation':
              print(f"Title: {annotation.url_citation.title}")
              print(f"URL: {annotation.url_citation.url}\n")
  ```

  ```typescript TypeScript theme={null}
  import OpenAI from 'openai';

  const client = new OpenAI({
    apiKey: process.env.BLACKBOX_API_KEY,
    baseURL: 'https://api.blackbox.ai',
  });

  async function main() {
    const response = await client.chat.completions.create({
      model: "blackboxai/blackbox-search",
      messages: [
        {
          role: "system",
          content: "You are a helpful assistant that provides accurate, up-to-date information.",
        },
        {
          role: "user",
          content: "What are the latest developments from OpenAI?",
        },
      ],
    });

    console.log(response.choices[0].message.content);

    // Access source citations
    if (response.choices[0].message.annotations) {
      console.log("\n--- Sources ---");
      response.choices[0].message.annotations.forEach(annotation => {
        if (annotation.type === 'url_citation') {
          console.log(`Title: ${annotation.url_citation.title}`);
          console.log(`URL: ${annotation.url_citation.url}\n`);
        }
      });
    }
  }

  main();
  ```
</CodeGroup>

The `blackbox-search` model automatically searches the web and provides responses with source citations in the `annotations` field. Learn more about [Web Search](/api-reference/web-search).

<Accordion title="View Example Output">
  ```
  ### Recent Model Releases and Updates
  OpenAI has been advancing its GPT series rapidly. In mid-November 2025, they released **GPT-5.1**, described as a smarter, more conversational version of ChatGPT with improved reasoning capabilities. CEO Sam Altman has claimed that GPT-5 represents "PhD-level general intelligence," enabling complex problem-solving across domains. [[1]](https://theconversation.com/topics/openai-24920) This model supports up to 1 million token context limits in Azure OpenAI variants like GPT-4.1. [[2]](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/whats-new?view=foundry-classic)

  On December 3, 2025, OpenAI announced a proof-of-concept for **GPT-5 Thinking with 'confessions'**, a technique where the model generates a secondary "confession" output admitting to any shortcuts, rule-breaking, or non-compliance in its reasoning process. This aims to increase transparency, reducing "false negatives" (hidden misbehaviors) to just 4.4% in tests. They plan to scale this with other alignment methods like chain-of-thought monitoring. [[3]](https://x.com/i/status/1996281172377436557)

  Additionally, specialized models include **GPT-5.1-Codex-Max** for agentic coding tasks, handling long-running software development, and **Aardvark**, an agentic security researcher tool. [[4]](https://www.newsbytesapp.com/news/business/openai) Azure OpenAI also launched **GPT-4.1 and GPT-4.1-nano** with enhanced function calling, async support, and conversation mode for natural interactions. [[2]](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/whats-new?view=foundry-classic)

  ### Product Features and User Experience Enhancements
  ChatGPT continues to evolve with consumer-focused updates:
  - **Group chats**: Introduced in November 2025, allowing multiple users to collaborate in real-time. [[5]](https://openai.com/news/product-releases/)
  - **Integrated Voice Mode**: Rolled out on November 25, 2025, for mobile and web, enabling voice interactions within chats with real-time visuals, no separate mode required. Users can toggle back to the original setup. [[6]](https://x.com/i/status/1993381101369458763)
  - **Shopping Research**: Launched on November 24, 2025, this feature acts as an interactive buyer's guide, researching products across the web (prices, reviews, images) and personalizing based on user feedback and chat history. Usage is nearly unlimited through the holidays to aid gift shopping. [[7]](https://x.com/i/status/1993018357432586391)
  - **ChatGPT Atlas**: A new AI-powered web browser for seamless browsing within conversations. [[4]](https://www.newsbytesapp.com/news/business/openai)

  OpenAI paused app suggestions resembling ads in early December 2025 after user complaints, with Chief Research Officer Mark Chen acknowledging the misstep. Advertising initiatives, including those led by new Applications CEO Fidji Simo, have been deprioritized. [[8]](https://techcrunch.com/2025/12/07/openai-says-its-turned-off-app-suggestions-that-look-like-ads/)

  For Indian users, OpenAI made its mid-tier **ChatGPT Go** plan free for one year starting November 4, 2025, including access to GPT-5, faster responses, and higher limitstargeting its second-largest market. [[9]](https://economictimes.indiatimes.com/topic/openai)

  ### Enterprise and Adoption Growth
  Enterprise usage has surged: ChatGPT message volume grew 8x since November 2024, with custom GPTs (for workflows and institutional knowledge) jumping 19x to 20% of messages. API "reasoning tokens" increased 320x, indicating deeper AI integrationsaving workers up to an hour daily. Examples include BBVA using 4,000+ custom GPTs. [[10]](https://techcrunch.com/2025/12/08/openai-boasts-enterprise-win-days-after-internal-code-red-on-google-threat/)

  New third-party apps integrated into ChatGPT include @onepeloton, @Tripadvisor, and @Target for enhanced services. [[11]](https://x.com/i/status/1993125078436135008)

  ### Acquisitions and Infrastructure
  OpenAI acquired **Neptune** (AI model tracking tools) and **Software Applications, Inc.** (AI interface for Apple devices) to bolster development. [[12]](https://www.reuters.com/technology/openai/)[[4]](https://www.newsbytesapp.com/news/business/openai) They also inked a deal with NEXTDC for an AI campus and GPU supercluster in Sydney. [[12]](https://www.reuters.com/technology/openai/)

  Funding includes SoftBank's $22.5 billion second installment in a $41 billion round. [[4]](https://www.newsbytesapp.com/news/business/openai) The **Stargate Project** advances massive AI data centers, like the Abilene, Texas facility drawing from local water sources. [[1]](https://theconversation.com/topics/openai-24920) A compute leasing deal with Oracle provides 4.5 GW of data center power. [[13]](https://www.computerworld.com/article/4015023/openai-latest-news-and-insights.html)

  ### Legal and Ethical Developments
  - A U.S. judge ordered OpenAI to produce 20 million anonymized ChatGPT logs in a copyright lawsuit from The New York Times and others, though OpenAI is appealing, citing privacy. [[12]](https://www.reuters.com/technology/openai/)
  - In India, OpenAI told the Delhi High Court that deleting ChatGPT training data would violate U.S. law amid an ANI copyright suit. [[13]](https://www.computerworld.com/article/4015023/openai-latest-news-and-insights.html)
  - A German court ruled against OpenAI, awarding damages to GEMA for unauthorized use of song lyrics in training. [[9]](https://economictimes.indiatimes.com/topic/openai)

  Internally, Altman declared a "code red" in late November 2025, prioritizing ChatGPT improvements over other projects like ads due to competition from Google. [[8]](https://techcrunch.com/2025/12/07/openai-says-its-turned-off-app-suggestions-that-look-like-ads/)

  ### Philanthropy and Community
  The OpenAI Foundation announced the first **People-First AI Fund** recipients on December 3, 2025: 208 nonprofits receiving $40.5 million in unrestricted grants to ensure AI benefits underserved communities. [[14]](https://x.com/i/status/1996258322304155695)

  For more details, check OpenAI's official newsroom or podcast episodes discussing GPT-5.1 training. [[15]](https://x.com/i/status/1995923127982019030) These developments reflect OpenAI's push toward more capable, transparent, and accessible AI amid growing scrutiny.

  --- Sources ---
  Title: 1
  URL: https://theconversation.com/topics/openai-24920

  Title: 2
  URL: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/whats-new?view=foundry-classic

  Title: 3
  URL: https://x.com/i/status/1996281172377436557

  Title: 4
  URL: https://www.newsbytesapp.com/news/business/openai

  Title: 5
  URL: https://openai.com/news/product-releases/

  Title: 6
  URL: https://x.com/i/status/1993381101369458763

  Title: 7
  URL: https://x.com/i/status/1993018357432586391

  Title: 8
  URL: https://techcrunch.com/2025/12/07/openai-says-its-turned-off-app-suggestions-that-look-like-ads/

  Title: 9
  URL: https://economictimes.indiatimes.com/topic/openai

  Title: 10
  URL: https://techcrunch.com/2025/12/08/openai-boasts-enterprise-win-days-after-internal-code-red-on-google-threat/

  Title: 11
  URL: https://x.com/i/status/1993125078436135008

  Title: 12
  URL: https://www.reuters.com/technology/openai/

  Title: 13
  URL: https://www.computerworld.com/article/4015023/openai-latest-news-and-insights.html

  Title: 14
  URL: https://x.com/i/status/1996258322304155695

  Title: 15
  URL: https://x.com/i/status/1995923127982019030
  ```
</Accordion>


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.blackbox.ai/llms.txt


# Parameters

> Learn about all available parameters for BLACKBOX AI API requests. Configure temperature, max tokens, top_p, and other model-specific settings.

Sampling parameters shape the token generation process of the model. You may send any parameters from the following list, as well as others, to BLACKBOX AI.

BLACKBOX AI will default to the values listed below if certain parameters are absent from your request (for example, `temperature` to 1.0). We will also transmit some provider-specific parameters, such as `safe_prompt` for Mistral or `raw_mode` for Hyperbolic directly to the respective providers if specified.

## Temperature

* Key: `temperature`

* Optional, **float**, 0.0 to 2.0

* Default: 1.0

* Explainer Video: [Watch](https://youtu.be/ezgqHnWvua8)

This setting influences the variety in the model's responses. Lower values lead to more predictable and typical responses, while higher values encourage more diverse and less common responses. At 0, the model always gives the same response for a given input.

## Top P

* Key: `top_p`

* Optional, **float**, 0.0 to 1.0

* Default: 1.0

* Explainer Video: [Watch](https://youtu.be/wQP-im_HInk)

This setting limits the model's choices to a percentage of likely tokens: only the top tokens whose probabilities add up to P. A lower value makes the model's responses more predictable, while the default setting allows for a full range of token choices. Think of it like a dynamic Top-K.

## Top K

* Key: `top_k`

* Optional, **integer**, 0 or above

* Default: 0

* Explainer Video: [Watch](https://youtu.be/EbZv6-N8Xlk)

This limits the model's choice of tokens at each step, making it choose from a smaller set. A value of 1 means the model will always pick the most likely next token, leading to predictable results. By default this setting is disabled, making the model to consider all choices.

## Frequency Penalty

* Key: `frequency_penalty`

* Optional, **float**, -2.0 to 2.0

* Default: 0.0

* Explainer Video: [Watch](https://youtu.be/p4gl6fqI0_w)

This setting aims to control the repetition of tokens based on how often they appear in the input. It tries to use less frequently those tokens that appear more in the input, proportional to how frequently they occur. Token penalty scales with the number of occurrences. Negative values will encourage token reuse.

## Presence Penalty

* Key: `presence_penalty`

* Optional, **float**, -2.0 to 2.0

* Default: 0.0

* Explainer Video: [Watch](https://youtu.be/MwHG5HL-P74)

Adjusts how often the model repeats specific tokens already used in the input. Higher values make such repetition less likely, while negative values do the opposite. Token penalty does not scale with the number of occurrences. Negative values will encourage token reuse.

## Repetition Penalty

* Key: `repetition_penalty`

* Optional, **float**, 0.0 to 2.0

* Default: 1.0

* Explainer Video: [Watch](https://youtu.be/LHjGAnLm3DM)

Helps to reduce the repetition of tokens from the input. A higher value makes the model less likely to repeat tokens, but too high a value can make the output less coherent (often with run-on sentences that lack small words). Token penalty scales based on original token's probability.

## Min P

* Key: `min_p`

* Optional, **float**, 0.0 to 1.0

* Default: 0.0

Represents the minimum probability for a token to be
considered, relative to the probability of the most likely token. (The value changes depending on the confidence level of the most probable token.) If your Min-P is set to 0.1, that means it will only allow for tokens that are at least 1/10th as probable as the best possible option.

## Top A

* Key: `top_a`

* Optional, **float**, 0.0 to 1.0

* Default: 0.0

Consider only the top tokens with "sufficiently high" probabilities based on the probability of the most likely token. Think of it like a dynamic Top-P. A lower Top-A value focuses the choices based on the highest probability token but with a narrower scope. A higher Top-A value does not necessarily affect the creativity of the output, but rather refines the filtering process based on the maximum probability.

## Seed

* Key: `seed`

* Optional, **integer**

If specified, the inferencing will sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed for some models.

## Max Tokens

* Key: `max_tokens`

* Optional, **integer**, 1 or above

This sets the upper limit for the number of tokens the model can generate in response. It won't produce more than this limit. The maximum value is the context length minus the prompt length.

## Logit Bias

* Key: `logit_bias`

* Optional, **map**

Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

## Logprobs

* Key: `logprobs`

* Optional, **boolean**

Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned.

## Top Logprobs

* Key: `top_logprobs`

* Optional, **integer**

An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. logprobs must be set to true if this parameter is used.

## Response Format

* Key: `response_format`

* Optional, **map**

Forces the model to produce specific output format. Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Note**: when using JSON mode, you should also instruct the model to produce JSON yourself via a system or user message.

## Structured Outputs

* Key: `structured_outputs`

* Optional, **boolean**

If the model can return structured outputs using response\_format json\_schema.

## Stop

* Key: `stop`

* Optional, **array**

Stop generation immediately if the model encounter any token specified in the stop array.

## Tools

* Key: `tools`

* Optional, **array**

Tool calling parameter, following OpenAI's tool calling request shape. For non-OpenAI providers, it will be transformed accordingly. To learn more about tool calling, see the [Tool & Function calling](/api-reference/tool-calling)

## Tool Choice

* Key: `tool_choice`

* Optional, **array**

Controls which (if any) tool is called by the model. 'none' means the model will not call any tool and instead generates a message. 'auto' means the model can pick between generating a message or calling one or more tools. 'required' means the model must call one or more tools. Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

## Parallel Tool Calls

* Key: `parallel_tool_calls`

* Optional, **boolean**

* Default: **true**

Whether to enable parallel function calling during tool use. If true, the model can call multiple functions simultaneously. If false, functions will be called sequentially. Only applies when tools are provided.

## Verbosity

* Key: `verbosity`

* Optional, **enum** (low, medium, high)

* Default: **medium**

Controls the verbosity and length of the model response. Lower values produce more concise responses, while higher values produce more detailed and comprehensive responses.


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.blackbox.ai/llms.txt



# Parameters

> Learn about all available parameters for BLACKBOX AI API requests. Configure temperature, max tokens, top_p, and other model-specific settings.

Sampling parameters shape the token generation process of the model. You may send any parameters from the following list, as well as others, to BLACKBOX AI.

BLACKBOX AI will default to the values listed below if certain parameters are absent from your request (for example, `temperature` to 1.0). We will also transmit some provider-specific parameters, such as `safe_prompt` for Mistral or `raw_mode` for Hyperbolic directly to the respective providers if specified.

## Temperature

* Key: `temperature`

* Optional, **float**, 0.0 to 2.0

* Default: 1.0

* Explainer Video: [Watch](https://youtu.be/ezgqHnWvua8)

This setting influences the variety in the model's responses. Lower values lead to more predictable and typical responses, while higher values encourage more diverse and less common responses. At 0, the model always gives the same response for a given input.

## Top P

* Key: `top_p`

* Optional, **float**, 0.0 to 1.0

* Default: 1.0

* Explainer Video: [Watch](https://youtu.be/wQP-im_HInk)

This setting limits the model's choices to a percentage of likely tokens: only the top tokens whose probabilities add up to P. A lower value makes the model's responses more predictable, while the default setting allows for a full range of token choices. Think of it like a dynamic Top-K.

## Top K

* Key: `top_k`

* Optional, **integer**, 0 or above

* Default: 0

* Explainer Video: [Watch](https://youtu.be/EbZv6-N8Xlk)

This limits the model's choice of tokens at each step, making it choose from a smaller set. A value of 1 means the model will always pick the most likely next token, leading to predictable results. By default this setting is disabled, making the model to consider all choices.

## Frequency Penalty

* Key: `frequency_penalty`

* Optional, **float**, -2.0 to 2.0

* Default: 0.0

* Explainer Video: [Watch](https://youtu.be/p4gl6fqI0_w)

This setting aims to control the repetition of tokens based on how often they appear in the input. It tries to use less frequently those tokens that appear more in the input, proportional to how frequently they occur. Token penalty scales with the number of occurrences. Negative values will encourage token reuse.

## Presence Penalty

* Key: `presence_penalty`

* Optional, **float**, -2.0 to 2.0

* Default: 0.0

* Explainer Video: [Watch](https://youtu.be/MwHG5HL-P74)

Adjusts how often the model repeats specific tokens already used in the input. Higher values make such repetition less likely, while negative values do the opposite. Token penalty does not scale with the number of occurrences. Negative values will encourage token reuse.

## Repetition Penalty

* Key: `repetition_penalty`

* Optional, **float**, 0.0 to 2.0

* Default: 1.0

* Explainer Video: [Watch](https://youtu.be/LHjGAnLm3DM)

Helps to reduce the repetition of tokens from the input. A higher value makes the model less likely to repeat tokens, but too high a value can make the output less coherent (often with run-on sentences that lack small words). Token penalty scales based on original token's probability.

## Min P

* Key: `min_p`

* Optional, **float**, 0.0 to 1.0

* Default: 0.0

Represents the minimum probability for a token to be
considered, relative to the probability of the most likely token. (The value changes depending on the confidence level of the most probable token.) If your Min-P is set to 0.1, that means it will only allow for tokens that are at least 1/10th as probable as the best possible option.

## Top A

* Key: `top_a`

* Optional, **float**, 0.0 to 1.0

* Default: 0.0

Consider only the top tokens with "sufficiently high" probabilities based on the probability of the most likely token. Think of it like a dynamic Top-P. A lower Top-A value focuses the choices based on the highest probability token but with a narrower scope. A higher Top-A value does not necessarily affect the creativity of the output, but rather refines the filtering process based on the maximum probability.

## Seed

* Key: `seed`

* Optional, **integer**

If specified, the inferencing will sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed for some models.

## Max Tokens

* Key: `max_tokens`

* Optional, **integer**, 1 or above

This sets the upper limit for the number of tokens the model can generate in response. It won't produce more than this limit. The maximum value is the context length minus the prompt length.

## Logit Bias

* Key: `logit_bias`

* Optional, **map**

Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

## Logprobs

* Key: `logprobs`

* Optional, **boolean**

Whether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned.

## Top Logprobs

* Key: `top_logprobs`

* Optional, **integer**

An integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. logprobs must be set to true if this parameter is used.

## Response Format

* Key: `response_format`

* Optional, **map**

Forces the model to produce specific output format. Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

**Note**: when using JSON mode, you should also instruct the model to produce JSON yourself via a system or user message.

## Structured Outputs

* Key: `structured_outputs`

* Optional, **boolean**

If the model can return structured outputs using response\_format json\_schema.

## Stop

* Key: `stop`

* Optional, **array**

Stop generation immediately if the model encounter any token specified in the stop array.

## Tools

* Key: `tools`

* Optional, **array**

Tool calling parameter, following OpenAI's tool calling request shape. For non-OpenAI providers, it will be transformed accordingly. To learn more about tool calling, see the [Tool & Function calling](/api-reference/tool-calling)

## Tool Choice

* Key: `tool_choice`

* Optional, **array**

Controls which (if any) tool is called by the model. 'none' means the model will not call any tool and instead generates a message. 'auto' means the model can pick between generating a message or calling one or more tools. 'required' means the model must call one or more tools. Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

## Parallel Tool Calls

* Key: `parallel_tool_calls`

* Optional, **boolean**

* Default: **true**

Whether to enable parallel function calling during tool use. If true, the model can call multiple functions simultaneously. If false, functions will be called sequentially. Only applies when tools are provided.

## Verbosity

* Key: `verbosity`

* Optional, **enum** (low, medium, high)

* Default: **medium**

Controls the verbosity and length of the model response. Lower values produce more concise responses, while higher values produce more detailed and comprehensive responses.


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.blackbox.ai/llms.txt




# Image Generation Models

<div className="w-full aspect-[10/7] grid grid-cols-2 rounded-2xl overflow-hidden">
  <div className="bg-black text-white p-6 grid grid-rows-[auto_auto_1fr] gap-4 h-full">
    <div>
      <h1 className="text-3xl font-bold text-white mb-2">BLACKBOX AI</h1>

      <p className="text-gray-400 text-base leading-relaxed">
        Explore the AI models available for generating high-quality images from text prompts.
      </p>
    </div>

    <div className="grid grid-cols-2 gap-6">
      <div>
        <div className="text-white-500 font-bold font-medium mb-2">MODELS</div>

        <div className="flex items-center gap-2 text-gray-400 text-base">
          <span>25+ Models</span>
        </div>
      </div>

      <div />
    </div>

    <div>
      <div className="text-white-500 font-medium mb-3">Features</div>

      <div className="grid grid-cols-1 gap-2">
        <div className="flex items-center gap-3 text-gray-400 text-sm">
          <span className="w-4 h-4 flex items-center justify-center text-white">
            <svg viewBox="0 0 24 24" fill="currentColor" className="w-4 h-4">
              <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z" />
            </svg>
          </span>

          <span>High-resolution output</span>
        </div>

        <div className="flex items-center gap-3 text-gray-400 text-sm">
          <span className="w-4 h-4 flex items-center justify-center text-white">
            <svg viewBox="0 0 24 24" fill="currentColor" className="w-4 h-4">
              <path d="M12 2l3.09 6.26L22 9.27l-5 4.87 1.18 6.88L12 17.77l-6.18 3.25L7 14.14 2 9.27l6.91-1.01L12 2z" />
            </svg>
          </span>

          <span>Multiple art styles</span>
        </div>

        <div className="flex items-center gap-3 text-gray-400 text-sm">
          <span className="w-4 h-4 flex items-center justify-center text-white">
            <svg viewBox="0 0 24 24" fill="currentColor" className="w-4 h-4">
              <path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm-2 15l-5-5 1.41-1.41L10 14.17l7.59-7.59L19 8l-9 9z" />
            </svg>
          </span>

          <span>Text-to-image generation</span>
        </div>

        <div className="flex items-center gap-3 text-gray-400 text-sm">
          <span className="w-4 h-4 flex items-center justify-center text-white">
            <svg viewBox="0 0 24 24" fill="currentColor" className="w-4 h-4">
              <path d="M7 2v11h3v9l7-12h-4l4-8z" />
            </svg>
          </span>

          <span>Lightning fast</span>
        </div>

        <div className="flex items-center gap-3 text-gray-400 text-sm">
          <span className="w-4 h-4 flex items-center justify-center text-white">
            <svg viewBox="0 0 24 24" fill="currentColor" className="w-4 h-4">
              <path d="M11.8 10.9c-2.27-.59-3-1.2-3-2.15 0-1.09 1.01-1.85 2.7-1.85 1.78 0 2.44.85 2.5 2.1h2.21c-.07-1.72-1.12-3.3-3.21-3.81V3h-3v2.16c-1.94.42-3.5 1.68-3.5 3.61 0 2.31 1.91 3.46 4.7 4.13 2.5.6 3 1.48 3 2.41 0 .69-.49 1.79-2.7 1.79-2.06 0-2.87-.92-2.98-2.1h-2.2c.12 2.19 1.76 3.42 3.68 3.83V21h3v-2.15c1.95-.37 3.5-1.5 3.5-3.55 0-2.84-2.43-3.81-4.7-4.4z" />
            </svg>
          </span>

          <span>Low cost</span>
        </div>
      </div>
    </div>
  </div>

  <div className=" bg-black p-4 relative overflow-hidden">
    <div
      className="absolute inset-0 w-full h-full"
      style={{
     backgroundImage: "url('/images/humming-bird-1.png')",
    backgroundSize: "contain",
      backgroundPosition: "center center",
      backgroundRepeat: "no-repeat",
       maskImage: "linear-gradient(to right, transparent 0%, black 100%)",
       WebkitMaskImage: "linear-gradient(to right, transparent 0%, black 100%)"
     }}
    />
  </div>
</div>

## Overview

Image generation models transform textual descriptions into rich, visual content. You can create everything from photorealistic images to artistic illustrations by simply describing what you want to see.

To generate an image, you will need to use one of the following Model IDs in your API request.

## Available Image Generation Models

| Model Name                  | Model ID                                            | Cost per Image | Prompt Length | Max Images per Request |
| --------------------------- | --------------------------------------------------- | -------------- | ------------- | ---------------------- |
| Blip                        | blackboxai/salesforce/blip                          | \$0.00022      | 2k chars      | 1                      |
| Blip 2                      | blackboxai/andreasjansson/blip-2                    | \$0.00160      | 2k chars      | 1                      |
| Clarity Upscaler            | blackboxai/philz1337x/clarity-upscaler              | \$0.01300      | 2k chars      | 1                      |
| Clip Embeddings             | blackboxai/krthr/clip-embeddings                    | \$0.00098      | 2k chars      | 1                      |
| Codeformer                  | blackboxai/sczhou/codeformer                        | \$0.00200      | 2k chars      | 1                      |
| Controlnet Scribble         | blackboxai/jagilley/controlnet-scribble             | \$0.00680      | 2k chars      | 1                      |
| Face To Many                | blackboxai/fofr/face-to-many                        | \$0.00570      | 2k chars      | 1                      |
| Flux 1.1 Pro                | blackboxai/black-forest-labs/flux-1.1-pro           | \$0.04000      | 2k chars      | 1                      |
| Flux 1.1 Pro Ultra          | blackboxai/black-forest-labs/flux-1.1-pro-ultra     | \$0.06000      | 2k chars      | 1                      |
| Flux Dev                    | blackboxai/black-forest-labs/flux-dev               | \$0.02500      | 2k chars      | 4                      |
| Flux Kontext Pro            | blackboxai/black-forest-labs/flux-kontext-pro       | \$0.04000      | 2k chars      | 1                      |
| Flux Pro                    | blackboxai/black-forest-labs/flux-pro               | \$0.05500      | 2k chars      | 1                      |
| Flux Schnell                | blackboxai/black-forest-labs/flux-schnell           | \$0.00300      | 2k chars      | 4                      |
| Flux.1 Dev                  | blackboxai/prunaai/flux.1-dev                       | \$0.00150      | 2k chars      | 1                      |
| Gfpgan                      | blackboxai/tencentarc/gfpgan                        | \$0.00220      | 2k chars      | 1                      |
| Gfpgan                      | blackboxai/xinntao/gfpgan                           | \$0.00053      | 2k chars      | 1                      |
| Grounding Dino              | blackboxai/adirik/grounding-dino                    | \$0.00098      | 2k chars      | 1                      |
| Hyper Flux 8Step            | blackboxai/bytedance/hyper-flux-8step               | \$0.01100      | 2k chars      | 4                      |
| Image Tagger                | blackboxai/pengdaqian2020/image-tagger              | \$0.00240      | 2k chars      | 1                      |
| Kandinsky 2.2               | blackboxai/ai-forever/kandinsky-2.2                 | \$0.12000      | 2k chars      | 4                      |
| Lama                        | blackboxai/allenhooo/lama                           | \$0.00035      | 2k chars      | 1                      |
| Llava 13B                   | blackboxai/yorickvp/llava-13b                       | \$0.00098      | 2k chars      | 1                      |
| Nano Banana                 | blackboxai/google/nano-banana                       | \$0.03900      | 2k chars      | 1                      |
| Nsfw\_Image\_Detection      | blackboxai/falcons-ai/nsfw\_image\_detection        | \$0.22500      | 2k chars      | 1                      |
| Openjourney                 | blackboxai/prompthero/openjourney                   | \$0.04700      | 2k chars      | 10                     |
| Proteus V0.2                | blackboxai/datacte/proteus-v0.2                     | \$0.02600      | 2k chars      | 4                      |
| Real Esrgan                 | blackboxai/nightmareai/real-esrgan                  | \$0.00240      | 2k chars      | 1                      |
| Real Esrgan A100            | blackboxai/daanelson/real-esrgan-a100               | \$0.00390      | 2k chars      | 1                      |
| Sdxl                        | blackboxai/stability-ai/sdxl                        | \$0.00360      | 2k chars      | 4                      |
| Sdxl Emoji                  | blackboxai/fofr/sdxl-emoji                          | \$0.00780      | 2k chars      | 4                      |
| Sdxl Lightning 4Step        | blackboxai/bytedance/sdxl-lightning-4step           | \$0.00140      | 2k chars      | 4                      |
| Stable Diffusion            | blackboxai/stability-ai/stable-diffusion            | \$0.00325      | 2k chars      | 4                      |
| Stable Diffusion Inpainting | blackboxai/stability-ai/stable-diffusion-inpainting | \$0.00180      | 2k chars      | 4                      |
| Text Extract Ocr            | blackboxai/abiruyt/text-extract-ocr                 | \$0.00230      | 2k chars      | 1                      |


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.blackbox.ai/llms.txt

# Video Generation Models

<div className="w-full aspect-[10/7] grid grid-cols-2 rounded-2xl overflow-hidden">
  <div className="bg-black text-white p-6 grid grid-rows-[auto_auto_1fr] gap-4 h-full">
    <div>
      <h1 className="text-3xl font-bold text-white mb-2">BLACKBOX AI</h1>

      <p className="text-gray-400 text-base leading-relaxed">
        Explore the AI models available for creating video clips from text prompts.
      </p>
    </div>

    <div className="grid grid-cols-2 gap-6">
      <div>
        <div className="text-white-500 font-bold font-medium mb-2">MODELS</div>

        <div className="flex items-center gap-2 text-gray-400 text-base">
          <span>Veo 2 | Veo 3 & Veo 3 Fast</span>
        </div>
      </div>

      <div />
    </div>

    <div>
      <div className="text-white-500 font-medium mb-3">Features</div>

      <div className="grid grid-cols-1 gap-2">
        <div className="flex items-center gap-3 text-gray-400 text-sm">
          <span className="w-4 h-4 flex items-center justify-center text-white">
            <svg viewBox="0 0 24 24" fill="currentColor" className="w-4 h-4">
              <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z" />
            </svg>
          </span>

          <span>High-resolution output</span>
        </div>

        <div className="flex items-center gap-3 text-gray-400 text-sm">
          <span className="w-4 h-4 flex items-center justify-center text-white">
            <svg viewBox="0 0 24 24" fill="currentColor" className="w-4 h-4">
              <path d="M12 2l3.09 6.26L22 9.27l-5 4.87 1.18 6.88L12 17.77l-6.18 3.25L7 14.14 2 9.27l6.91-1.01L12 2z" />
            </svg>
          </span>

          <span>Multiple art styles</span>
        </div>

        <div className="flex items-center gap-3 text-gray-400 text-sm">
          <span className="w-4 h-4 flex items-center justify-center text-white">
            <svg viewBox="0 0 24 24" fill="currentColor" className="w-4 h-4">
              <path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm-2 15l-5-5 1.41-1.41L10 14.17l7.59-7.59L19 8l-9 9z" />
            </svg>
          </span>

          <span>Text-to-video generation</span>
        </div>

        <div className="flex items-center gap-3 text-gray-400 text-sm">
          <span className="w-4 h-4 flex items-center justify-center text-white">
            <svg viewBox="0 0 24 24" fill="currentColor" className="w-4 h-4">
              <path d="M7 2v11h3v9l7-12h-4l4-8z" />
            </svg>
          </span>

          <span>Lightning fast</span>
        </div>

        <div className="flex items-center gap-3 text-gray-400 text-sm">
          <span className="w-4 h-4 flex items-center justify-center text-white">
            <svg viewBox="0 0 24 24" fill="currentColor" className="w-4 h-4">
              <path d="M11.8 10.9c-2.27-.59-3-1.2-3-2.15 0-1.09 1.01-1.85 2.7-1.85 1.78 0 2.44.85 2.5 2.1h2.21c-.07-1.72-1.12-3.3-3.21-3.81V3h-3v2.16c-1.94.42-3.5 1.68-3.5 3.61 0 2.31 1.91 3.46 4.7 4.13 2.5.6 3 1.48 3 2.41 0 .69-.49 1.79-2.7 1.79-2.06 0-2.87-.92-2.98-2.1h-2.2c.12 2.19 1.76 3.42 3.68 3.83V21h3v-2.15c1.95-.37 3.5-1.5 3.5-3.55 0-2.84-2.43-3.81-4.7-4.4z" />
            </svg>
          </span>

          <span>Low cost</span>
        </div>
      </div>
    </div>
  </div>

  <div className=" bg-black p-4 relative overflow-hidden">
    <div
      className="absolute inset-0 w-full h-full"
      style={{
     backgroundImage: "url('/images/video-icon.png')",
    backgroundSize: "contain",
      backgroundPosition: "center center",
      backgroundRepeat: "no-repeat",
       maskImage: "linear-gradient(to right, transparent 0%, black 100%)",
       WebkitMaskImage: "linear-gradient(to right, transparent 0%, black 100%)"
     }}
    />
  </div>
</div>

## Overview

Video generation models take text-to-video synthesis to the next level, allowing you to create short video clips from a simple text description. This feature is perfect for creating dynamic content for social media, presentations, or storytelling.

## Available Video Generation Models

| Model Name | Model ID                     | Cost              | Maximum Prompt Length | Max videos per Request |
| ---------- | ---------------------------- | ----------------- | --------------------- | ---------------------- |
| Veo 2      | blackboxai/google/veo-2      | \$0.50 per second | 2k chars              | 1                      |
| Veo 3      | blackboxai/google/veo-3      | \$0.75 per second | 2k chars              | 1                      |
| Veo 3 Fast | blackboxai/google/veo-3-fast | \$3.20 per video  | 2k chars              | 1                      |


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.blackbox.ai/llms.txt

